{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQDup52LepGf"
      },
      "source": [
        "# Imports, install and mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VuiFTKNQlYG",
        "outputId": "b0f02528-6c53-4e7c-ff68-c0b79ce5de6c"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# import sys\n",
        "# my_local_drive='/content/gdrive/MyDrive/SL2024/datas'\n",
        "# # Ajout du path pour les librairies, fonctions et données\n",
        "# sys.path.append(my_local_drive)\n",
        "# # Se positionner sur le répertoire associé\n",
        "# %cd $my_local_drive\n",
        "# # %pwd\n",
        "# print(\"DRIVE MOUNTED\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcIJjGMol68d"
      },
      "source": [
        "<!--  -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IdMkskBXNLUF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (5.2.0) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
          ]
        }
      ],
      "source": [
        "# ! pip install cuda\n",
        "# ! pip install torch_geometric\n",
        "# ! pip install nxontology\n",
        "# ! pip install tensordict\n",
        "# ! pip install pandas\n",
        "# ! pip install tensorflow\n",
        "# ! pip install scipy\n",
        "# ! pip install matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import ComplEx\n",
        "from torch_geometric.data import Data\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zsSHTMaQjRm"
      },
      "source": [
        "# Settings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZUA9xMQQjRm",
        "outputId": "074d9313-168f-444d-c817-4bb87dc9d0df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# ComplEx embeddings :\n",
        "\n",
        "hidden_channels = 10\n",
        "batch_size = 1000\n",
        "epochs = 10\n",
        "\n",
        "file_path = \"/home/elliot/Documents/ESL2024/data/little_genes_to_phenotypes_iric.tsv\"\n",
        "\n",
        "params_save_name = f\"ComplEx_HC_{hidden_channels}_BS_{batch_size}_epochs_{epochs}\"\n",
        "params_save_path = \"/home/elliot/Documents/ESL2024/code/models_parameters/ComplEx\"+params_save_name\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (5.2.0) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbutzelliot\u001b[0m (\u001b[33mesl2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem at: /tmp/ipykernel_75497/1336610842.py 1 <module>\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# set the wandb project where this run will be logged\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mComplEx on little_Os_to_GO_iric\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# track hyperparameters and run metadata\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marchitecture\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mComplEx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhead - 10000 genes_to_phenotypes_iric.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_channels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:1210\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m logger\n\u001b[1;32m   1209\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterrupted\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m-> 1210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1212\u001b[0m     error_seen \u001b[38;5;241m=\u001b[39m e\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:1187\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001b[0m\n\u001b[1;32m   1185\u001b[0m except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1187\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py:818\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    816\u001b[0m run_start_handle \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mdeliver_run_start(run\u001b[38;5;241m.\u001b[39m_run_obj)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# TODO: add progress to let user know we are doing something\u001b[39;00m\n\u001b[0;32m--> 818\u001b[0m run_start_result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_start_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_start_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    820\u001b[0m     run_start_handle\u001b[38;5;241m.\u001b[39mabandon()\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py:283\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interface\u001b[38;5;241m.\u001b[39m_transport_keepalive_failed():\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransport failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 283\u001b[0m found, abandoned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_and_clear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m found:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Always update progress to 100% when done\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on_progress \u001b[38;5;129;01mand\u001b[39;00m progress_handle \u001b[38;5;129;01mand\u001b[39;00m progress_sent:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py:130\u001b[0m, in \u001b[0;36m_MailboxSlot._get_and_clear\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_and_clear\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[pb\u001b[38;5;241m.\u001b[39mResult], \u001b[38;5;28mbool\u001b[39m]:\n\u001b[1;32m    129\u001b[0m     found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m             found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py:126\u001b[0m, in \u001b[0;36m_MailboxSlot._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
            "File \u001b[0;32m/usr/lib/python3.8/threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "wandb.init(\n",
        "    # set the wandb project where this run will be logged\n",
        "    project=\"ComplEx on little_Os_to_GO_iric\",\n",
        "    \n",
        "    # track hyperparameters and run metadata\n",
        "    config={\n",
        "    \"architecture\": \"ComplEx\",\n",
        "    \"dataset\": \"head - 10000 genes_to_phenotypes_iric.tsv\",\n",
        "    \"epochs\": epochs,\n",
        "    'hidden_channels' : hidden_channels,\n",
        "    'batch_size' : batch_size\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DATAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnktwewNevXS"
      },
      "source": [
        "## Reading and mapping graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghP3_JJzbZAA"
      },
      "source": [
        "What we want : Create a Data object with all the properties I want to use later\n",
        "\n",
        "\t- x (tensorised and processed node attributes) (Not for now)\n",
        "\t- edge_index (a tensor of shape (num_edges, 2) indicates the source node index and the destination node index)\n",
        "\t- y (desired edge labels - optional, can be defined as node labels if needed) (Not for now)\n",
        "\t- any other things you want to use later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GBF6eQpLQmk6",
        "outputId": "bce4f453-fe6e-405f-ffc9-33fb9f8c97f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>predicate</th>\n",
              "      <th>object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OsNippo01g010050</td>\n",
              "      <td>gene ontology</td>\n",
              "      <td>GO:0031267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OsNippo01g010050</td>\n",
              "      <td>gene ontology</td>\n",
              "      <td>GO:0006886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OsNippo01g010050</td>\n",
              "      <td>gene ontology</td>\n",
              "      <td>GO:0005622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OsNippo01g010050</td>\n",
              "      <td>gene ontology</td>\n",
              "      <td>GO:0005623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OsNippo01g010050</td>\n",
              "      <td>gene ontology</td>\n",
              "      <td>GO:0090630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>OsNippo01g223000</td>\n",
              "      <td>gene ontology</td>\n",
              "      <td>GO:0005784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>OsNippo01g223050</td>\n",
              "      <td>gene ontology</td>\n",
              "      <td>GO:0005634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>OsNippo01g223050</td>\n",
              "      <td>gene ontology</td>\n",
              "      <td>GO:0005737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>OsNippo01g223050</td>\n",
              "      <td>gene ontology</td>\n",
              "      <td>GO:0003676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>OsNippo01g223050</td>\n",
              "      <td>gene ontology</td>\n",
              "      <td>GO:0090305</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10001 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                subject      predicate      object\n",
              "0      OsNippo01g010050  gene ontology  GO:0031267\n",
              "1      OsNippo01g010050  gene ontology  GO:0006886\n",
              "2      OsNippo01g010050  gene ontology  GO:0005622\n",
              "3      OsNippo01g010050  gene ontology  GO:0005623\n",
              "4      OsNippo01g010050  gene ontology  GO:0090630\n",
              "...                 ...            ...         ...\n",
              "9996   OsNippo01g223000  gene ontology  GO:0005784\n",
              "9997   OsNippo01g223050  gene ontology  GO:0005634\n",
              "9998   OsNippo01g223050  gene ontology  GO:0005737\n",
              "9999   OsNippo01g223050  gene ontology  GO:0003676\n",
              "10000  OsNippo01g223050  gene ontology  GO:0090305\n",
              "\n",
              "[10001 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "iric = pd.read_csv(file_path, delimiter='\\t', names = ['subject', 'predicate','object'])\n",
        "display(iric)\n",
        "\n",
        "# Mapping entities to ids\n",
        "\n",
        "entity_set = set(iric['object']).union(set(iric['subject']))\n",
        "entity_to_mapping = {entity: int(i) for i, entity in enumerate(entity_set)}\n",
        "relation_set = set(iric['predicate'])\n",
        "relation_to_mapping = {relation: int(i) for i, relation in enumerate(relation_set)}\n",
        "\n",
        "mapped_iric = iric.copy()\n",
        "mapped_iric['object'] = mapped_iric['object'].apply(lambda x: entity_to_mapping[x])\n",
        "mapped_iric['subject'] = mapped_iric['subject'].apply(lambda x: entity_to_mapping[x])\n",
        "mapped_iric['predicate'] = mapped_iric['predicate'].apply(lambda x: relation_to_mapping[x])\n",
        "\n",
        "# display(mapped_iric)\n",
        "\n",
        "# print('OK')\n",
        "# print(\"Minima in mappings :\")\n",
        "# print('subject :', min(mapped_iric['subject']))\n",
        "# print('predicate :',min(mapped_iric['predicate']))\n",
        "# print('object :',min(mapped_iric['object']))\n",
        "\n",
        "# print(entity_to_mapping)\n",
        "# print(relation_to_mapping)\n",
        "\n",
        "mapping_to_entity = {v: k for k, v in entity_to_mapping.items()}\n",
        "mapping_to_relation = {v: k for k, v in relation_to_mapping.items()}\n",
        "\n",
        "# print(\"Mapping to entity dict :\",mapping_to_entity)\n",
        "# print(\"Mapping to relation dict\",mapping_to_relation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVemQRTkczW7"
      },
      "source": [
        "## Building init vars for Data :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4Zh3HoEc6cU",
        "outputId": "eb445852-a342-46d2-98a4-ce447df0c8ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "EDGE INDEX : \n",
            " tensor([[ 409,  409,  409,  ..., 1982, 1982, 1982],\n",
            "        [ 779, 1868, 2623,  ..., 3025, 3066, 1578]])\n",
            "\n",
            "EDGES ATTRIBUTES : \n",
            " tensor([0, 0, 0,  ..., 0, 0, 0])\n",
            "\n",
            "DATASET :\n",
            " Data(edge_index=[2, 10001], edge_attr=[10001], num_nodes=3343)\n",
            "\n",
            "Dataset looks valid ? \n",
            " True\n"
          ]
        }
      ],
      "source": [
        "# # Initial nodes states :\n",
        "# x = torch.ones(len(entity_set), 1)  # Chaque nœud a 1 pour état initial\n",
        "# print('X : \\n',x)\n",
        "\n",
        "# Edges index\n",
        "heads = list(mapped_iric['subject'])\n",
        "tails = list(mapped_iric['object'])\n",
        "edge_index = torch.tensor([heads,tails], dtype=torch.long)\n",
        "print('\\nEDGE INDEX : \\n',edge_index)\n",
        "\n",
        "# edges states\n",
        "edge_attributes = torch.tensor(mapped_iric['predicate'])\n",
        "print('\\nEDGES ATTRIBUTES : \\n',edge_attributes)\n",
        "\n",
        "iric_pyg = Data(\n",
        "                # x = x,\n",
        "                num_nodes = len(entity_set),\n",
        "                edge_index = edge_index,\n",
        "                edge_attr = edge_attributes)\n",
        "print('\\nDATASET :\\n',iric_pyg)\n",
        "\n",
        "\n",
        "print(\"\\nDataset looks valid ? \\n\",iric_pyg.validate(raise_on_error=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yVnwVs4h0HE"
      },
      "source": [
        "## Setting up datas and model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcWLKtXxCoBK"
      },
      "source": [
        "## Splitting dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liA7PxgDac4i",
        "outputId": "a38fc686-f884-4147-8f6e-3101f3cc41ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hole Dataset :\n",
            " Data(edge_index=[2, 10001], edge_attr=[10001], num_nodes=3343)\n",
            "\n",
            "Train:\n",
            "Data(edge_index=[2, 8001], edge_attr=[8001], num_nodes=3343, edge_label=[8001], edge_label_index=[2, 8001])\n",
            "\n",
            "Test :\n",
            "Data(edge_index=[2, 9001], edge_attr=[9001], num_nodes=3343, edge_label=[2000], edge_label_index=[2, 2000])\n",
            "\n",
            "Validation :\n",
            "Data(edge_index=[2, 8001], edge_attr=[8001], num_nodes=3343, edge_label=[2000], edge_label_index=[2, 2000])\n",
            "Number of edges in datasets : \n",
            "  Train: 8001\n",
            "\n",
            "  Test : 2000\n",
            "\n",
            "  Validation : 2000\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "\n",
        "transform = RandomLinkSplit(\n",
        "                            num_val = 0.1,\n",
        "                            num_test = 0.1,\n",
        "                            is_undirected=False,\n",
        "                            add_negative_train_samples=False,\n",
        "                            )\n",
        "\n",
        "train_data, val_data, test_data = transform(iric_pyg)\n",
        "\n",
        "print(f\"Hole Dataset :\\n {iric_pyg}\\n\\nTrain:\\n{train_data}\\n\\nTest :\\n{test_data}\\n\\nValidation :\\n{val_data}\")\n",
        "# Il ne faut pas regarder num_edges parce que RLS cache les arêtes mais ne les sort pas du graph.\n",
        "# print(f\"Number of edges in datasets : \\n  Hole Dataset : {iric_pyg.num_edges}\\n\\n  Train: {train_data.num_edges}\\n\\n  Test : {test_data.num_edges}\\n\\n  Validation : {val_data.num_edges}\")\n",
        "print(f\"Number of edges in datasets : \\n  Train: {list(train_data.edge_label.size())[0]}\\n\\n  Test : {list(test_data.edge_label.size())[0]}\\n\\n  Validation : {list(val_data.edge_label.size())[0]}\")\n",
        "\n",
        "train_data = train_data.to(device)\n",
        "val_data = val_data.to(device)\n",
        "test_data = test_data.to(device)\n",
        "\n",
        "# print('\\n\\n',train_data.num_nodes)\n",
        "# print(train_data.num_edge_types)\n",
        "# print(train_data.__dict__)\n",
        "# print(train_data.edge_index[0].size())\n",
        "# print(train_data.edge_index[1].size())\n",
        "# print(train_data.edge_attr.size())\n",
        "# print(train_data.edge_attr)\n",
        "# print(train_data.num_nodes)\n",
        "# print(train_data.edge_index.size()[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODELS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmfPJcuTi3Ul"
      },
      "source": [
        "## Iniating models and loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ3Oi0vsQjRr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n"
          ]
        }
      ],
      "source": [
        "# Initiating models\n",
        "\n",
        "complex_model = ComplEx(\n",
        "    num_nodes=train_data.num_nodes,\n",
        "    num_relations = train_data.edge_index.size()[1],\n",
        "    hidden_channels=hidden_channels,\n",
        ").to(device)\n",
        "\n",
        "# Initiaing loader\n",
        "head_index = train_data.edge_index[0]\n",
        "tail_index = train_data.edge_index[1]\n",
        "rel_type = train_data.edge_attr\n",
        "\n",
        "loader = complex_model.loader(\n",
        "    head_index = head_index,\n",
        "    tail_index = tail_index,\n",
        "    rel_type = rel_type,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# initiating optimizers\n",
        "complex_optimizer = optim.Adam(complex_model.parameters())\n",
        "\n",
        "print(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(data, model):\n",
        "    model.eval()\n",
        "    return model.test(\n",
        "        head_index=test_data.edge_index[0],\n",
        "        tail_index=test_data.edge_index[1],\n",
        "        rel_type=test_data.edge_attr,\n",
        "        batch_size=1000,\n",
        "        k=10,\n",
        "    )\n",
        "\n",
        "def train(model, optimizer):\n",
        "    model.train()\n",
        "    total_loss = total_examples = 0\n",
        "    for head_index, rel_type, tail_index in loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(head_index, rel_type, tail_index)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * head_index.numel()\n",
        "        total_examples += head_index.numel()\n",
        "    return total_loss / total_examples\n",
        "\n",
        "def plot_loss(loss_list):\n",
        "    plt.plot(loss_list, label='Loss')\n",
        "    plt.title('Evolution des Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_loss_log(loss_list):\n",
        "    plt.semilogy(loss_list, label='Loss')\n",
        "    plt.title('Evolution des Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def running_mean(list,\n",
        "                 half_window: int # Number of elements that the function will consider\n",
        "                                  # ahead and behind the position X to calculate running mean at X.\n",
        "                 ):\n",
        "    running_means = []\n",
        "\n",
        "    for i in range(0,len(list)):\n",
        "\n",
        "        left_bound = max(0,i-half_window)\n",
        "        right_bound = min(len(list)-1, i + half_window)\n",
        "        sublist = list[left_bound:right_bound+1]\n",
        "        running_means.append(sum(sublist)/len(sublist))\n",
        "\n",
        "    return running_means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv6TIchaQjRr",
        "outputId": "12dd55ba-9b78-4b6a-d457-d4bb97cc8688"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9001/9001 [00:10<00:00, 866.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start Test Mean Rank: 1671.30, Start Test MRR: 0.0029, Start Test Hits@10: 0.0031\n",
            "Epoch: 001, Loss: 0.6931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9001/9001 [00:10<00:00, 897.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001, Val Mean Rank: 1492.04 Val MRR: 0.0048, Val Hits@10: 0.0080\n",
            "Epoch: 002, Loss: 0.6931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9001/9001 [00:10<00:00, 882.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 002, Val Mean Rank: 1323.60 Val MRR: 0.0073, Val Hits@10: 0.0107\n",
            "Epoch: 003, Loss: 0.6931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9001/9001 [00:09<00:00, 914.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 003, Val Mean Rank: 1151.69 Val MRR: 0.0124, Val Hits@10: 0.0222\n",
            "Epoch: 004, Loss: 0.6931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9001/9001 [00:10<00:00, 892.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 004, Val Mean Rank: 979.59 Val MRR: 0.0214, Val Hits@10: 0.0422\n",
            "Epoch: 005, Loss: 0.6931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9001/9001 [00:10<00:00, 863.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 005, Val Mean Rank: 811.16 Val MRR: 0.0394, Val Hits@10: 0.0734\n",
            "Epoch: 006, Loss: 0.6931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9001/9001 [00:10<00:00, 860.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 006, Val Mean Rank: 656.05 Val MRR: 0.0636, Val Hits@10: 0.1192\n",
            "Epoch: 007, Loss: 0.6931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 97/9001 [00:00<00:10, 826.69it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mround\u001b[39m(epochs\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 17\u001b[0m     rank, mrr, hits \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplex_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Mean Rank: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrank\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal MRR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmrr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Hits@10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhits\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal Mean Rank\u001b[39m\u001b[38;5;124m\"\u001b[39m : rank, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal MRR\u001b[39m\u001b[38;5;124m\"\u001b[39m : mrr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhits@10\u001b[39m\u001b[38;5;124m\"\u001b[39m: hits})\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[12], line 4\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(data, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest\u001b[39m(data, model):\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtail_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_geometric/nn/kge/base.py:125\u001b[0m, in \u001b[0;36mKGEModel.test\u001b[0;34m(self, head_index, rel_type, tail_index, batch_size, k, log)\u001b[0m\n\u001b[1;32m    123\u001b[0m tail_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_nodes, device\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ts \u001b[38;5;129;01min\u001b[39;00m tail_indices\u001b[38;5;241m.\u001b[39msplit(batch_size):\n\u001b[0;32m--> 125\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    126\u001b[0m rank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((torch\u001b[38;5;241m.\u001b[39mcat(scores)\u001b[38;5;241m.\u001b[39margsort(\n\u001b[1;32m    127\u001b[0m     descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m==\u001b[39m t)\u001b[38;5;241m.\u001b[39mnonzero()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    128\u001b[0m mean_ranks\u001b[38;5;241m.\u001b[39mappend(rank)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch_geometric/nn/kge/complex.py:67\u001b[0m, in \u001b[0;36mComplEx.forward\u001b[0;34m(self, head_index, rel_type, tail_index)\u001b[0m\n\u001b[1;32m     65\u001b[0m rel_re \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel_emb(rel_type)\n\u001b[1;32m     66\u001b[0m rel_im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel_emb_im(rel_type)\n\u001b[0;32m---> 67\u001b[0m tail_re \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtail_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m tail_im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_emb_im(tail_index)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (triple_dot(head_re, rel_re, tail_re) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     71\u001b[0m         triple_dot(head_im, rel_re, tail_im) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     72\u001b[0m         triple_dot(head_re, rel_im, tail_im) \u001b[38;5;241m-\u001b[39m\n\u001b[1;32m     73\u001b[0m         triple_dot(head_im, rel_im, tail_re))\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "torch.set_grad_enabled(True)\n",
        "\n",
        "complex_model.reset_parameters()\n",
        "complex_model.to(device)\n",
        "\n",
        "start_rank, start_mrr, start_hits_at_10 = test(test_data, model=complex_model)\n",
        "print(f'Start Test Mean Rank: {start_rank:.2f}, Start Test MRR: {start_mrr:.4f}, '\n",
        "      f'Start Test Hits@10: {start_hits_at_10:.4f}')\n",
        "\n",
        "losses = []\n",
        "for epoch in range(0, epochs+1):\n",
        "    loss = train(model=complex_model, optimizer=complex_optimizer)\n",
        "    losses.append(loss)\n",
        "    wandb.log({\"loss\": loss})\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
        "\n",
        "    if epoch % epochs/100 == 0:\n",
        "        rank, mrr, hits = test(val_data, model=complex_model)\n",
        "        print(f'Epoch: {epoch:03d}, Val Mean Rank: {rank:.2f}',\n",
        "              f'Val MRR: {mrr:.4f}, Val Hits@10: {hits:.4f}')\n",
        "        wandb.log({\"Val Mean Rank\" : rank, \"Val MRR\" : mrr, \"hits@10\": hits})\n",
        "\n",
        "rank, mrr, hits_at_10 = test(test_data, model=complex_model)\n",
        "\n",
        "torch.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(complex_model.state_dict(), params_save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
