{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebutz/miniconda3/envs/pyg2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n",
      "\n",
      "Loading ontology...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/ebutz/ESL2024/code/utils' )\n",
    "import optuna\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.sampler import NegativeSampling\n",
    "import torch_geometric.transforms as T\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import ComplEx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from nxontology.imports import from_file\n",
    "import wandb\n",
    "from play_with_complex import *\n",
    "from data_utils import *\n",
    "from train_utils import *\n",
    "from model_utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
    "import play_with_complex as pwc\n",
    "\n",
    "\n",
    "#Â Iric\n",
    "iric_path = '/home/ebutz/ESL2024/data/full_iric/iric.csv'\n",
    "mapped_iric_path  = '/home/ebutz/ESL2024/data/full_iric/altailed_mapped_iric.pickle'\n",
    "altails_dict_path = '/home/ebutz/ESL2024/data/full_iric/altail_iric_DICT.pickle'\n",
    "check_dicts = True\n",
    "\n",
    "ontology_path = '/home/ebutz/ESL2024/data/go-basic.json.gz'\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Device: '{device}'\")\n",
    "\n",
    "\n",
    "# # ------------- Loading ontology ------------- #\n",
    "\n",
    "print(\"\\nLoading ontology...\")\n",
    "nxo = from_file(ontology_path)\n",
    "nxo.freeze()\n",
    "pwc.nxo = nxo\n",
    "\n",
    "df = pd.read_csv(iric_path, index_col=0, dtype=str)\n",
    "df['source_node'] = df.index\n",
    "df.columns = [x.lower() for x in df.columns]\n",
    "go_map = get_nodelist(df, 'go')\n",
    "go_to_idx = {node: i for i, node in enumerate(go_map)}\n",
    "idx_to_go = {i: node for i, node in enumerate(go_map)}\n",
    "\n",
    "# # ------------- Making global variables accessibles to pwc ------------- #\n",
    "\n",
    "pwc.map_to_GO        = idx_to_go\n",
    "pwc.mapped_alt_tails = None\n",
    "pwc.device           = device\n",
    "\n",
    "# ------------- Model setup ------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(config, loader, model, criterion, compute_all_metrics=False, loader_type='validation', stopper_metric=False):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given data loader.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : object\n",
    "        An object containing the configuration parameters for the model.    \n",
    "    loader : DataLoader\n",
    "        The data loader to evaluate the model on.\n",
    "    model : Model\n",
    "        The model to evaluate.\n",
    "    criterion : callable\n",
    "        The loss function to use for evaluation.\n",
    "    compute_all_metrics : bool, optional\n",
    "        Whether to compute all metrics or partially. Default is False.\n",
    "    loader_type : str, optional\n",
    "        The type of the loader ('validation' or 'test'). Default is 'validation'.\n",
    "    stopper_metric : str or bool, optional\n",
    "        The metric that dictates when to stop training. If False, only the loss is computed. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple of the evaluation metric and the loss, depending on the value of `stopper_metric`.\n",
    "        If compute_all_metrics is True, the function logs all metrics to W&B.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Evaluation...\")\n",
    "    model.eval()\n",
    "    num_neg_samples = loader.neg_sampling.amount\n",
    "    with torch.no_grad():\n",
    "        if stopper_metric or compute_all_metrics:\n",
    "            ground_truths = torch.tensor([], device='cpu')\n",
    "            preds = torch.tensor([], device='cpu')\n",
    "            indexes = torch.tensor([], device='cpu')\n",
    "            total_loss, total_examples = 0, 0\n",
    "            index_end = loader.batch_size\n",
    "\n",
    "        for sampled_data in loader:\n",
    "            sampled_data = sampled_data.to(device)\n",
    "\n",
    "            batch_size = len(sampled_data[config.labels['tail']].dst_pos_index)\n",
    "            pred = model(sampled_data, config)\n",
    "            pos_samples = torch.ones(batch_size, device=device)\n",
    "            neg_samples = torch.zeros(num_neg_samples*batch_size, device=device)\n",
    "            ground_truth = torch.cat((pos_samples, neg_samples))\n",
    "\n",
    "            if stopper_metric or compute_all_metrics: # Store preds and truths for all batches, and compute indices to calc metrics\n",
    "                index_pos = torch.arange(end=index_end, start=index_end-batch_size) # index for predictions with pos. ground_truth\n",
    "                index_neg = torch.arange(end=index_end, start=index_end-batch_size).repeat_interleave(num_neg_samples)\n",
    "                index = torch.cat((index_pos, index_neg))\n",
    "                indexes = torch.cat((indexes, index.to('cpu')))\n",
    "                preds = torch.cat((preds, pred.to('cpu')))\n",
    "                ground_truths = torch.cat((ground_truths, ground_truth.to('cpu')))\n",
    "                index_end += batch_size\n",
    "\n",
    "            eval_loss = criterion(pred, ground_truth, gamma=config.gamma, alpha=config.alpha)\n",
    "\n",
    "            # if not stopper_metric: # Just logging loss\n",
    "            #     wandb.log({\"running_val_loss\": eval_loss})\n",
    "            #     break\n",
    "            # else:\n",
    "            total_loss += float(eval_loss) * pred.numel() \n",
    "            total_examples += pred.numel()\n",
    "            eval_loss = total_loss / total_examples\n",
    "\n",
    "            # if stopper_metric and not compute_all_metrics:\n",
    "            #     if index_end >= 2048: # Compute approx. intermediate metric on a few datapoints to speed up hyperopt process\n",
    "            #         break \n",
    "\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        if stopper_metric and not compute_all_metrics: # Compute only the metric that dictates stopping\n",
    "            indexes = indexes.long()\n",
    "\n",
    "            # # Log heatmap between prediction and ground truth. Useful for visualization / debugging. overhead 0.2s per epoch for a single sample.\n",
    "            # heatmap = heatmaps(preds, ground_truths, indexes) \n",
    "            # wandb.log({f\"heatmap\": wandb.Image(heatmap)})\n",
    "            # heatmap.close() # Free up memory\n",
    "\n",
    "            match stopper_metric:\n",
    "                case \"val_loss\":\n",
    "                    eval_loss = total_loss / total_examples\n",
    "                    return eval_loss\n",
    "                \n",
    "                case \"mrr\":\n",
    "                    mrr = RetrievalMRR().to(device)\n",
    "                    return mrr(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_10\":\n",
    "                    hit_at_10 = RetrievalHitRate(top_k=10).to(device)\n",
    "                    return hit_at_10(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_5\":\n",
    "                    hit_at_5 = RetrievalHitRate(top_k=5).to(device)\n",
    "                    return hit_at_5(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_3\":\n",
    "                    hit_at_3 = RetrievalHitRate(top_k=3).to(device)\n",
    "                    return hit_at_3(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_1\":\n",
    "                    hit_at_1 = RetrievalHitRate(top_k=1).to(device)\n",
    "                    return hit_at_1(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case _:\n",
    "                    raise ValueError(f\"Unrecognized stopper metric: '{stopper_metric}'\")\n",
    "                \n",
    "        if compute_all_metrics: # Compute all metrics at the end of training\n",
    "            indexes = indexes.long()\n",
    "            mrr = RetrievalMRR().to(device)\n",
    "            hit_at_10 = RetrievalHitRate(top_k=10).to(device)\n",
    "            hit_at_5 = RetrievalHitRate(top_k=5).to(device)\n",
    "            hit_at_3 = RetrievalHitRate(top_k=3).to(device)\n",
    "            hit_at_1 = RetrievalHitRate(top_k=1).to(device)\n",
    "            \n",
    "            mrr = mrr(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_10 = hit_at_10(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_5 = hit_at_5(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_3 = hit_at_3(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_1 = hit_at_1(preds, ground_truths, indexes=indexes)\n",
    "\n",
    "            wandb.log({\n",
    "                f\"{loader_type}MRR\": mrr, f\"{loader_type}hit_at_10\": hit_at_10, f\"{loader_type}hit_at_5\": hit_at_5, f\"{loader_type}hit_at_3\": hit_at_3, f\"{loader_type}hit_at_1\": hit_at_1\n",
    "            })\n",
    "\n",
    "    return mrr, eval_loss\n",
    "\n",
    "def train(config, train_loader, val_loader, model, criterion, optimizer, early_stopper, labels_type = 'usual', eval_period = 0):\n",
    "    for epoch in range(config.epochs):\n",
    "        total_loss = total_examples = 0\n",
    "\n",
    "        for sampled_data in tqdm(train_loader, desc=\"Training\"):\n",
    "\n",
    "            sampled_data = sampled_data.to(device)\n",
    "            pred = model(sampled_data, config)\n",
    "            pos_samples  = torch.ones(len(sampled_data[config.labels['tail']].dst_pos_index), device=device)\n",
    "            neg_samples  = torch.zeros(len(sampled_data[config.labels['tail']].dst_neg_index.view(-1)), device=device) # As many zeroes as there are negative samples * batch_size\n",
    "            ground_truth = torch.cat((pos_samples, neg_samples))\n",
    "\n",
    "            false_tails = sampled_data[config.labels['tail']].dst_neg_index.view(-1)\n",
    "            true_tails = sampled_data['go']['dst_pos_index']\n",
    "            true_tails = torch.repeat_interleave(true_tails,int(false_tails.size()[0]/true_tails.size()[0]))\n",
    "\n",
    "\n",
    "            if labels_type == 'linsim':\n",
    "                \n",
    "                lin_neg_samples = pwc.lin_sims_for_batch(true_tails, false_tails)\n",
    "\n",
    "                pos_samples = pos_samples.to(device)\n",
    "                lin_neg_samples = lin_neg_samples.to(device)\n",
    "\n",
    "                lin_ground_truth = torch.cat((pos_samples, lin_neg_samples))\n",
    "\n",
    "            if labels_type == 'rand_linsim':\n",
    "\n",
    "                linsims = pwc.lin_sims_for_batch(true_tails, false_tails)\n",
    "                lin_neg_samples = pwc.shuffle_tensor(linsims)\n",
    "                lin_neg_samples.to(device)\n",
    "                \n",
    "                lin_ground_truth = torch.cat((pos_samples, lin_neg_samples))\n",
    "\n",
    "            if labels_type == 'gaussian_noise':\n",
    "                # Add gaussian noise to pos_samples to simulate noisy labels. Added noise must be negative and not exceed 1.\n",
    "                ground_truth += torch.normal(mean=0, std=1, size=(len(ground_truth),), device=device)\n",
    "                # apply sigmoid\n",
    "                ground_truth = torch.sigmoid(ground_truth)\n",
    "\n",
    "            if labels_type == 'usual':\n",
    "                ground_truth = torch.sigmoid(ground_truth)\n",
    "\n",
    "            if criterion == torch.nn.modules.loss.MSELoss:\n",
    "                loss = criterion(pred, lin_ground_truth)\n",
    "            elif criterion == sigmoid_focal_loss:\n",
    "                loss = criterion(pred, lin_ground_truth, gamma=config.gamma, alpha=config.alpha)\n",
    "            else :\n",
    "                print(\"Unrecognized loss !\")\n",
    "\n",
    "            wandb.log({\"loss\": loss})\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += float(loss) * pred.numel()\n",
    "            total_examples += pred.numel()\n",
    "        train_loss = total_loss / total_examples\n",
    "        print(f\"Epoch: {epoch:03d}, Avg. Loss: {train_loss:.10f}\")\n",
    "\n",
    "\n",
    "        # scheduler.step()\n",
    "        if eval_period:\n",
    "            if epoch%eval_period == 0:\n",
    "                # Compute metrics and check for early stopping\n",
    "                score, val_loss = evaluate(config, val_loader, model, criterion, stopper_metric=config.stopper_metric, compute_all_metrics= True)\n",
    "                wandb.log({\"avg_loss\": train_loss, \"val_loss\": val_loss, f\"{config.stopper_metric}\": score})\n",
    "\n",
    "        # early_stopper(score)\n",
    "        # if early_stopper.early_stop:\n",
    "        #     print(\"Early stopping triggered at epoch\", epoch)\n",
    "        #     break\n",
    "\n",
    "    print(\"Training done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN Baseline VS LinSim VS Noise With MSE : usual labels with sigmoid_focal_loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbutzelliot\u001b[0m (\u001b[33mesl2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ebutz/ESL2024/wandb/run-20240612_163045-rfot1uzx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/rfot1uzx' target=\"_blank\">usual labels with sigmoid_focal_loss</a></strong> to <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/rfot1uzx' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/rfot1uzx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebutz/ESL2024/code/utils/train_utils.py:184: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_links['source_node'] = df_links.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  genes={ x=[72335, 29] },\n",
      "  go={ x=[42979, 3] },\n",
      "  po={ x=[1662, 2] },\n",
      "  traito={ x=[1636, 1] },\n",
      "  prosite_profiles={ x=[627, 1] },\n",
      "  prosite_patterns={ x=[652, 1] },\n",
      "  superfamily={ x=[957, 1] },\n",
      "  panther={ x=[5971, 1] },\n",
      "  prints={ x=[420, 1] },\n",
      "  (genes, interacts_with, genes)={ edge_index=[2, 1120849] },\n",
      "  (genes, gene_ontology, go)={ edge_index=[2, 169248] },\n",
      "  (genes, trait_ontology, traito)={ edge_index=[2, 15080] },\n",
      "  (genes, plant_ontology, po)={ edge_index=[2, 6125] },\n",
      "  (genes, profile, prosite_profiles)={ edge_index=[2, 12239] },\n",
      "  (genes, pattern, prosite_patterns)={ edge_index=[2, 6677] },\n",
      "  (genes, family, superfamily)={ edge_index=[2, 20742] },\n",
      "  (genes, panther_id, panther)={ edge_index=[2, 25319] },\n",
      "  (genes, prints_id, prints)={ edge_index=[2, 4365] },\n",
      "  (go, is_a, go)={ edge_index=[2, 136436] },\n",
      "  (po, is_a, po)={ edge_index=[2, 3548] },\n",
      "  (traito, is_a, traito)={ edge_index=[2, 3770] },\n",
      "  (go, rev_gene_ontology, genes)={ edge_index=[2, 169248] },\n",
      "  (traito, rev_trait_ontology, genes)={ edge_index=[2, 15080] },\n",
      "  (po, rev_plant_ontology, genes)={ edge_index=[2, 6125] },\n",
      "  (prosite_profiles, rev_profile, genes)={ edge_index=[2, 12239] },\n",
      "  (prosite_patterns, rev_pattern, genes)={ edge_index=[2, 6677] },\n",
      "  (superfamily, rev_family, genes)={ edge_index=[2, 20742] },\n",
      "  (panther, rev_panther_id, genes)={ edge_index=[2, 25319] },\n",
      "  (prints, rev_prints_id, genes)={ edge_index=[2, 4365] }\n",
      ")\n",
      "data look valid :  True\n",
      "Function 'split_data' executed in 0.0126s\n",
      "Function 'build_dataloaders' executed in 0.1384s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|ââââââââââ| 80/80 [00:31<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Avg. Loss: 0.1406409677\n",
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: 100%|ââââââââââ| 80/80 [00:30<00:00,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Avg. Loss: 0.1406251067\n",
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done.\n",
      "Evaluation...\n",
      "Evaluation...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>ââ</td></tr><tr><td>hit_at_10</td><td>ââ</td></tr><tr><td>loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>val_loss</td><td>ââ</td></tr><tr><td>validationMRR</td><td>ââ</td></tr><tr><td>validationhit_at_1</td><td>ââ</td></tr><tr><td>validationhit_at_10</td><td>ââ</td></tr><tr><td>validationhit_at_3</td><td>ââ</td></tr><tr><td>validationhit_at_5</td><td>ââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss</td><td>0.14063</td></tr><tr><td>hit_at_10</td><td>0.41154</td></tr><tr><td>loss</td><td>0.14063</td></tr><tr><td>val_loss</td><td>0.16594</td></tr><tr><td>validationMRR</td><td>0.41154</td></tr><tr><td>validationhit_at_1</td><td>0.27442</td></tr><tr><td>validationhit_at_10</td><td>0.72245</td></tr><tr><td>validationhit_at_3</td><td>0.45789</td></tr><tr><td>validationhit_at_5</td><td>0.57159</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">usual labels with sigmoid_focal_loss</strong> at: <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/rfot1uzx' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/rfot1uzx</a><br/> View project at: <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240612_163045-rfot1uzx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Â Which labels should be used ?\n",
    "#Â Choices are : 'usual', 'rand_linsim', linsim', 'gaussian_noise', 'usual'.\n",
    "labels_type = 'usual'\n",
    "\n",
    "#Â How many epochs between 2 time-consuming evaluations ?\n",
    "eval_period = 1\n",
    "\n",
    "#Â Wandb\n",
    "xp_name = 'GNN Baseline VS LinSim VS Noise With MSE'\n",
    "run_name = f'{labels_type} labels with sigmoid_focal_loss'\n",
    "print(xp_name,':',run_name)\n",
    "\n",
    "run = wandb.init(project=xp_name, name = run_name)\n",
    "config = wandb.config\n",
    "config.labels_type = labels_type\n",
    "config.val_ratio=0.1\n",
    "config.homogeneous=False\n",
    "config.scorelist_size=1000\n",
    "config.split_ratio=0.8\n",
    "config.val_ratio=0.1\n",
    "config.test_ratio=0.1\n",
    "config.num_neighbors=[70,55,13,89,85]\n",
    "config.batch_size=1024\n",
    "config.train_neg_sampling_ratio=224\n",
    "config.epochs=2\n",
    "config.disjoint_train_ratio=0.6\n",
    "config.lr=0.0015308253347932983\n",
    "config.stopper_metric= 'hit_at_10'\n",
    "config.stopper_direction=\"maximize\"\n",
    "config.stopper_patience=5\n",
    "config.stopper_frequency=1\n",
    "config.stopper_relative_delta=0.05\n",
    "config.gamma=1.3\n",
    "config.alpha=0.42680473078813763\n",
    "config.gnn_layer='ResGatedGraphConv'\n",
    "config.dropout=0.1\n",
    "config.norm='DiffGroupNorm'\n",
    "config.aggregation = 'min'\n",
    "config.hidden_channels=115\n",
    "config.num_layers=3\n",
    "config.attention_heads=4\n",
    "config.homogeneous = False\n",
    "config.labels = {'head' : 'genes', 'relation' : 'gene_ontology', 'tail' : 'go'}\n",
    "\n",
    "data = load_iric_data('/home/ebutz/ESL2024/data/full_iric/iric.csv', featureless=False)\n",
    "data  = T.ToUndirected(merge=True)(data) # Convert the graph to an undirected graph. Creates reverse edges for each edge.\n",
    "data = T.RemoveDuplicatedEdges()(data) # Remove duplicated edges\n",
    "print(data)\n",
    "print('data look valid : ',data.validate())\n",
    "\n",
    "train_data, val_data, test_data = split_data(data, config)\n",
    "train_loader, val_loader, test_loader = build_dataloaders(train_data, val_data, test_data, config)\n",
    "\n",
    "\n",
    "gnn_layers = get_gnn_layers(config)\n",
    "norm_layers = get_norm_layers(config, len(data.node_types))\n",
    "\n",
    "model = Model(config, data, norm_layers, gnn_layers).to(device)\n",
    "\n",
    "criterion = sigmoid_focal_loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "early_stopper = EarlyStopper(frequency=config.stopper_frequency, patience=config.stopper_patience,\n",
    "                             direction=config.stopper_direction, relative_delta=config.stopper_relative_delta)\n",
    "\n",
    "train(config, train_loader, val_loader, model, criterion, optimizer, early_stopper, labels_type=config.labels_type, eval_period = eval_period)\n",
    "evaluate(config,  val_loader, model, criterion, compute_all_metrics=False, loader_type='validation', stopper_metric='hit_at_10')\n",
    "evaluate(config, test_loader, model, criterion, compute_all_metrics=False, loader_type='test'      , stopper_metric='hit_at_10')\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN Baseline VS LinSim VS Noise With MSE : usual labels and MSE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2ac24k2x) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">usual labels and MSE</strong> at: <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/2ac24k2x' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/2ac24k2x</a><br/> View project at: <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240612_164000-2ac24k2x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2ac24k2x). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ebutz/ESL2024/wandb/run-20240612_164908-qtf5ti30</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/qtf5ti30' target=\"_blank\">usual labels and MSE</a></strong> to <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/qtf5ti30' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/qtf5ti30</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebutz/ESL2024/code/utils/train_utils.py:184: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_links['source_node'] = df_links.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  genes={ x=[72335, 29] },\n",
      "  go={ x=[42979, 3] },\n",
      "  po={ x=[1662, 2] },\n",
      "  traito={ x=[1636, 1] },\n",
      "  prosite_profiles={ x=[627, 1] },\n",
      "  prosite_patterns={ x=[652, 1] },\n",
      "  superfamily={ x=[957, 1] },\n",
      "  panther={ x=[5971, 1] },\n",
      "  prints={ x=[420, 1] },\n",
      "  (genes, interacts_with, genes)={ edge_index=[2, 1120849] },\n",
      "  (genes, gene_ontology, go)={ edge_index=[2, 169248] },\n",
      "  (genes, trait_ontology, traito)={ edge_index=[2, 15080] },\n",
      "  (genes, plant_ontology, po)={ edge_index=[2, 6125] },\n",
      "  (genes, profile, prosite_profiles)={ edge_index=[2, 12239] },\n",
      "  (genes, pattern, prosite_patterns)={ edge_index=[2, 6677] },\n",
      "  (genes, family, superfamily)={ edge_index=[2, 20742] },\n",
      "  (genes, panther_id, panther)={ edge_index=[2, 25319] },\n",
      "  (genes, prints_id, prints)={ edge_index=[2, 4365] },\n",
      "  (go, is_a, go)={ edge_index=[2, 136436] },\n",
      "  (po, is_a, po)={ edge_index=[2, 3548] },\n",
      "  (traito, is_a, traito)={ edge_index=[2, 3770] },\n",
      "  (go, rev_gene_ontology, genes)={ edge_index=[2, 169248] },\n",
      "  (traito, rev_trait_ontology, genes)={ edge_index=[2, 15080] },\n",
      "  (po, rev_plant_ontology, genes)={ edge_index=[2, 6125] },\n",
      "  (prosite_profiles, rev_profile, genes)={ edge_index=[2, 12239] },\n",
      "  (prosite_patterns, rev_pattern, genes)={ edge_index=[2, 6677] },\n",
      "  (superfamily, rev_family, genes)={ edge_index=[2, 20742] },\n",
      "  (panther, rev_panther_id, genes)={ edge_index=[2, 25319] },\n",
      "  (prints, rev_prints_id, genes)={ edge_index=[2, 4365] }\n",
      ")\n",
      "data look valid :  True\n",
      "Function 'split_data' executed in 0.0114s\n",
      "Function 'build_dataloaders' executed in 0.1425s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/80 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 910.00 MiB. GPU 0 has a total capacty of 10.91 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 10.32 GiB memory in use. Of the allocated memory 9.54 GiB is allocated by PyTorch, and 253.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 67\u001b[0m\n\u001b[1;32m     62\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlr)\n\u001b[1;32m     64\u001b[0m early_stopper \u001b[38;5;241m=\u001b[39m EarlyStopper(frequency\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstopper_frequency, patience\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstopper_patience,\n\u001b[1;32m     65\u001b[0m                              direction\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstopper_direction, relative_delta\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstopper_relative_delta)\n\u001b[0;32m---> 67\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_period\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meval_period\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m evaluate(config,  val_loader, model, criterion, compute_all_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, loader_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m, stopper_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhit_at_10\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     69\u001b[0m evaluate(config, test_loader, model, criterion, compute_all_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, loader_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m      , stopper_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhit_at_10\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 138\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config, train_loader, val_loader, model, criterion, optimizer, early_stopper, labels_type, eval_period)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sampled_data \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    137\u001b[0m     sampled_data \u001b[38;5;241m=\u001b[39m sampled_data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 138\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     pos_samples  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(sampled_data[config\u001b[38;5;241m.\u001b[39mlabels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtail\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdst_pos_index), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    140\u001b[0m     neg_samples  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(sampled_data[config\u001b[38;5;241m.\u001b[39mlabels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtail\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdst_neg_index\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;66;03m# As many zeroes as there are negative samples * batch_size\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ESL2024/code/utils/model_utils.py:262\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, sampled_data, config)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sampled_data, config):\n\u001b[1;32m    261\u001b[0m     z_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(sampled_data\u001b[38;5;241m.\u001b[39mx_dict, sampled_data\u001b[38;5;241m.\u001b[39medge_index_dict)\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampled_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ESL2024/code/utils/model_utils.py:155\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, z_dict, sampled_data, config)\u001b[0m\n\u001b[1;32m    153\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm:\n\u001b[0;32m--> 155\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m    157\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch_geometric/nn/norm/diff_group_norm.py:80\u001b[0m, in \u001b[0;36mDiffGroupNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [N, G]\u001b[39;00m\n\u001b[1;32m     79\u001b[0m out \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# [N, G, F]\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, G, F)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# [N, F]\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlamda \u001b[38;5;241m*\u001b[39m out\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/functional.py:2478\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2476\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2479\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 910.00 MiB. GPU 0 has a total capacty of 10.91 GiB of which 600.06 MiB is free. Including non-PyTorch memory, this process has 10.32 GiB memory in use. Of the allocated memory 9.54 GiB is allocated by PyTorch, and 253.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#Â Which labels should be used ?\n",
    "#Â Choices are : 'usual', 'rand_linsim', linsim', 'gaussian_noise', 'usual'.\n",
    "labels_type = 'usual'\n",
    "\n",
    "#Â How many epochs between 2 time-consuming evaluations ?\n",
    "eval_period = 1\n",
    "\n",
    "#Â Wandb\n",
    "xp_name = 'GNN Baseline VS LinSim VS Noise With MSE'\n",
    "run_name = f'{labels_type} labels and MSE'\n",
    "print(xp_name,':',run_name)\n",
    "\n",
    "run = wandb.init(project=xp_name, name = run_name)\n",
    "config = wandb.config\n",
    "config.labels_type = labels_type\n",
    "config.val_ratio=0.1\n",
    "config.homogeneous=False\n",
    "config.scorelist_size=1000\n",
    "config.split_ratio=0.8\n",
    "config.val_ratio=0.1\n",
    "config.test_ratio=0.1\n",
    "config.num_neighbors=[70,55,13,89,85]\n",
    "config.batch_size=1024\n",
    "config.train_neg_sampling_ratio=224\n",
    "config.epochs=2\n",
    "config.disjoint_train_ratio=0.6\n",
    "config.lr=0.0015308253347932983\n",
    "config.stopper_metric= 'hit_at_10'\n",
    "config.stopper_direction=\"maximize\"\n",
    "config.stopper_patience=5\n",
    "config.stopper_frequency=1\n",
    "config.stopper_relative_delta=0.05\n",
    "config.gamma=1.3\n",
    "config.alpha=0.42680473078813763\n",
    "config.gnn_layer='ResGatedGraphConv'\n",
    "config.dropout=0.1\n",
    "config.norm='DiffGroupNorm'\n",
    "config.aggregation = 'min'\n",
    "config.hidden_channels=115\n",
    "config.num_layers=3\n",
    "config.attention_heads=4\n",
    "config.homogeneous = False\n",
    "config.labels = {'head' : 'genes', 'relation' : 'gene_ontology', 'tail' : 'go'}\n",
    "\n",
    "data = load_iric_data('/home/ebutz/ESL2024/data/full_iric/iric.csv', featureless=False)\n",
    "data  = T.ToUndirected(merge=True)(data) # Convert the graph to an undirected graph. Creates reverse edges for each edge.\n",
    "data = T.RemoveDuplicatedEdges()(data) # Remove duplicated edges\n",
    "print(data)\n",
    "print('data look valid : ',data.validate())\n",
    "\n",
    "train_data, val_data, test_data = split_data(data, config)\n",
    "train_loader, val_loader, test_loader = build_dataloaders(train_data, val_data, test_data, config)\n",
    "\n",
    "\n",
    "gnn_layers = get_gnn_layers(config)\n",
    "norm_layers = get_norm_layers(config, len(data.node_types))\n",
    "\n",
    "model = Model(config, data, norm_layers, gnn_layers).to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "early_stopper = EarlyStopper(frequency=config.stopper_frequency, patience=config.stopper_patience,\n",
    "                             direction=config.stopper_direction, relative_delta=config.stopper_relative_delta)\n",
    "\n",
    "train(config, train_loader, val_loader, model, criterion, optimizer, early_stopper, labels_type=config.labels_type, eval_period = eval_period)\n",
    "evaluate(config,  val_loader, model, criterion, compute_all_metrics=False, loader_type='validation', stopper_metric='hit_at_10')\n",
    "evaluate(config, test_loader, model, criterion, compute_all_metrics=False, loader_type='test'      , stopper_metric='hit_at_10')\n",
    "\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
