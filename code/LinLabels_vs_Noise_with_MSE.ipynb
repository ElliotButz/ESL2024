{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n",
      "\n",
      "Loading ontology...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/ebutz/ESL2024/code/utils' )\n",
    "import optuna\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.sampler import NegativeSampling\n",
    "import torch_geometric.transforms as T\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import ComplEx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from nxontology.imports import from_file\n",
    "import wandb\n",
    "from play_with_complex import *\n",
    "from data_utils import *\n",
    "from train_utils import *\n",
    "from model_utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
    "import play_with_complex as pwc\n",
    "\n",
    "epochs = 15\n",
    "# Iric\n",
    "iric_path = '/home/ebutz/ESL2024/data/full_iric/iric.csv'\n",
    "mapped_iric_path  = '/home/ebutz/ESL2024/data/full_iric/altailed_mapped_iric.pickle'\n",
    "altails_dict_path = '/home/ebutz/ESL2024/data/full_iric/altail_iric_DICT.pickle'\n",
    "check_dicts = True\n",
    "\n",
    "ontology_path = '/home/ebutz/ESL2024/data/go-basic.json.gz'\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Device: '{device}'\")\n",
    "\n",
    "\n",
    "# # ------------- Loading ontology ------------- #\n",
    "\n",
    "print(\"\\nLoading ontology...\")\n",
    "nxo = from_file(ontology_path)\n",
    "nxo.freeze()\n",
    "pwc.nxo = nxo\n",
    "\n",
    "df = pd.read_csv(iric_path, index_col=0, dtype=str)\n",
    "df['source_node'] = df.index\n",
    "df.columns = [x.lower() for x in df.columns]\n",
    "go_map = get_nodelist(df, 'go')\n",
    "go_to_idx = {node: i for i, node in enumerate(go_map)}\n",
    "idx_to_go = {i: node for i, node in enumerate(go_map)}\n",
    "\n",
    "# # ------------- Making global variables accessibles to pwc ------------- #\n",
    "\n",
    "pwc.map_to_GO        = idx_to_go\n",
    "pwc.mapped_alt_tails = None\n",
    "pwc.device           = device\n",
    "\n",
    "# ------------- Model setup ------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(config, loader, model, criterion, compute_all_metrics=False, loader_type='validation', stopper_metric=False):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given data loader.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : object\n",
    "        An object containing the configuration parameters for the model.    \n",
    "    loader : DataLoader\n",
    "        The data loader to evaluate the model on.\n",
    "    model : Model\n",
    "        The model to evaluate.\n",
    "    criterion : callable\n",
    "        The loss function to use for evaluation.\n",
    "    compute_all_metrics : bool, optional\n",
    "        Whether to compute all metrics or partially. Default is False.\n",
    "    loader_type : str, optional\n",
    "        The type of the loader ('validation' or 'test'). Default is 'validation'.\n",
    "    stopper_metric : str or bool, optional\n",
    "        The metric that dictates when to stop training. If False, only the loss is computed. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple of the evaluation metric and the loss, depending on the value of `stopper_metric`.\n",
    "        If compute_all_metrics is True, the function logs all metrics to W&B.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Evaluation...\")\n",
    "    model.eval()\n",
    "    num_neg_samples = loader.neg_sampling.amount\n",
    "    with torch.no_grad():\n",
    "        if stopper_metric or compute_all_metrics:\n",
    "            ground_truths = torch.tensor([], device='cpu')\n",
    "            preds = torch.tensor([], device='cpu')\n",
    "            indexes = torch.tensor([], device='cpu')\n",
    "            total_loss, total_examples = 0, 0\n",
    "            index_end = loader.batch_size\n",
    "\n",
    "        for sampled_data in loader:\n",
    "            sampled_data = sampled_data.to(device)\n",
    "\n",
    "            batch_size = len(sampled_data[config.labels['tail']].dst_pos_index)\n",
    "            pred = model(sampled_data, config)\n",
    "            pos_samples = torch.ones(batch_size, device=device)\n",
    "            neg_samples = torch.zeros(num_neg_samples*batch_size, device=device)\n",
    "            ground_truth = torch.cat((pos_samples, neg_samples))\n",
    "\n",
    "            if stopper_metric or compute_all_metrics: # Store preds and truths for all batches, and compute indices to calc metrics\n",
    "                index_pos = torch.arange(end=index_end, start=index_end-batch_size) # index for predictions with pos. ground_truth\n",
    "                index_neg = torch.arange(end=index_end, start=index_end-batch_size).repeat_interleave(num_neg_samples)\n",
    "                index = torch.cat((index_pos, index_neg))\n",
    "                indexes = torch.cat((indexes, index.to('cpu')))\n",
    "                preds = torch.cat((preds, pred.to('cpu')))\n",
    "                ground_truths = torch.cat((ground_truths, ground_truth.to('cpu')))\n",
    "                index_end += batch_size\n",
    "\n",
    "            # eval_loss = criterion(pred, ground_truth, gamma=config.gamma, alpha=config.alpha)\n",
    "\n",
    "            # if not stopper_metric: # Just logging loss\n",
    "            #     wandb.log({\"running_val_loss\": eval_loss})\n",
    "            #     break\n",
    "            # else: !\n",
    "            # total_loss += float(eval_loss) * pred.numel() \n",
    "            # total_examples += pred.numel()\n",
    "            # eval_loss = total_loss / total_examples\n",
    "\n",
    "            # if stopper_metric and not compute_all_metrics:\n",
    "            #     if index_end >= 2048: # Compute approx. intermediate metric on a few datapoints to speed up hyperopt process\n",
    "            #         break \n",
    "\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        if stopper_metric and not compute_all_metrics: # Compute only the metric that dictates stopping\n",
    "            indexes = indexes.long()\n",
    "\n",
    "            # # Log heatmap between prediction and ground truth. Useful for visualization / debugging. overhead 0.2s per epoch for a single sample.\n",
    "            # heatmap = heatmaps(preds, ground_truths, indexes) \n",
    "            # wandb.log({f\"heatmap\": wandb.Image(heatmap)})\n",
    "            # heatmap.close() # Free up memory\n",
    "\n",
    "            match stopper_metric:\n",
    "                # case \"val_loss\":\n",
    "                #     eval_loss = total_loss / total_examples\n",
    "                #     return eval_loss\n",
    "                \n",
    "                case \"mrr\":\n",
    "                    mrr = RetrievalMRR().to(device)\n",
    "                    return mrr(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_10\":\n",
    "                    hit_at_10 = RetrievalHitRate(top_k=10).to(device)\n",
    "                    return hit_at_10(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_5\":\n",
    "                    hit_at_5 = RetrievalHitRate(top_k=5).to(device)\n",
    "                    return hit_at_5(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_3\":\n",
    "                    hit_at_3 = RetrievalHitRate(top_k=3).to(device)\n",
    "                    return hit_at_3(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_1\":\n",
    "                    hit_at_1 = RetrievalHitRate(top_k=1).to(device)\n",
    "                    return hit_at_1(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case _:\n",
    "                    raise ValueError(f\"Unrecognized stopper metric: '{stopper_metric}'\")\n",
    "                \n",
    "        if compute_all_metrics: # Compute all metrics at the end of training\n",
    "            indexes = indexes.long()\n",
    "            mrr = RetrievalMRR().to(device)\n",
    "            hit_at_10 = RetrievalHitRate(top_k=10).to(device)\n",
    "            hit_at_5 = RetrievalHitRate(top_k=5).to(device)\n",
    "            hit_at_3 = RetrievalHitRate(top_k=3).to(device)\n",
    "            hit_at_1 = RetrievalHitRate(top_k=1).to(device)\n",
    "            \n",
    "            mrr = mrr(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_10 = hit_at_10(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_5 = hit_at_5(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_3 = hit_at_3(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_1 = hit_at_1(preds, ground_truths, indexes=indexes)\n",
    "\n",
    "            wandb.log({\n",
    "                f\"{loader_type}MRR\": mrr, f\"{loader_type}hit_at_10\": hit_at_10, f\"{loader_type}hit_at_5\": hit_at_5, f\"{loader_type}hit_at_3\": hit_at_3, f\"{loader_type}hit_at_1\": hit_at_1\n",
    "            })\n",
    "\n",
    "            eval_loss = 1\n",
    "\n",
    "    return mrr, eval_loss\n",
    "\n",
    "def train(config, train_loader, val_loader, model, criterion, loss_name, optimizer, early_stopper, labels_type = 'usual', eval_period = 0, xp_name =\"not indicated\"):\n",
    "    print(\"LOSS :\", criterion)\n",
    "    print(\"XP name :\", xp_name)\n",
    "    for epoch in range(config.epochs):\n",
    "        total_loss = total_examples = 0\n",
    "\n",
    "        for sampled_data in tqdm(train_loader, desc=\"Training\"):\n",
    "\n",
    "            sampled_data = sampled_data.to(device)\n",
    "            pred = model(sampled_data, config)\n",
    "            pos_samples  = torch.ones(len(sampled_data[config.labels['tail']].dst_pos_index), device=device)\n",
    "            neg_samples  = torch.zeros(len(sampled_data[config.labels['tail']].dst_neg_index.view(-1)), device=device) # As many zeroes as there are negative samples * batch_size\n",
    "            ground_truth = torch.cat((pos_samples, neg_samples))\n",
    "\n",
    "            false_tails = sampled_data[config.labels['tail']].dst_neg_index.view(-1)\n",
    "            true_tails = sampled_data['go']['dst_pos_index']\n",
    "            true_tails = torch.repeat_interleave(true_tails,int(false_tails.size()[0]/true_tails.size()[0]))\n",
    "\n",
    "\n",
    "            if labels_type == 'linsim':\n",
    "                \n",
    "                lin_neg_samples = pwc.lin_sims_for_batch(true_tails, false_tails)\n",
    "\n",
    "                pos_samples = pos_samples.to(device)\n",
    "                lin_neg_samples = lin_neg_samples.to(device)\n",
    "\n",
    "                ground_truth = torch.cat((pos_samples, lin_neg_samples))\n",
    "\n",
    "            if labels_type == 'rand_linsim':\n",
    "\n",
    "                linsims = pwc.lin_sims_for_batch(true_tails, false_tails)\n",
    "                lin_neg_samples = pwc.shuffle_tensor(linsims)\n",
    "                lin_neg_samples.to(device)\n",
    "                pos_samples.to(device)\n",
    "                \n",
    "                ground_truth = torch.cat((pos_samples, lin_neg_samples))\n",
    "                ground_truth.to(device)\n",
    "\n",
    "            if labels_type == 'gaussian_noise':\n",
    "                # Add gaussian noise to pos_samples to simulate noisy labels. Added noise must be negative and not exceed 1.\n",
    "                ground_truth += torch.normal(mean=0, std=1, size=(len(ground_truth),), device=device).to(device)\n",
    "                # apply sigmoid\n",
    "                ground_truth = torch.sigmoid(ground_truth).to(device)\n",
    "\n",
    "            if labels_type == 'usual':\n",
    "                ground_truth = torch.sigmoid(ground_truth).to(device)\n",
    "\n",
    "            if loss_name == \"MSE\":\n",
    "                loss = criterion(pred, ground_truth)\n",
    "            elif loss_name == \"sigmoid focal\":\n",
    "                loss = criterion(pred, ground_truth, gamma=config.gamma, alpha=config.alpha)\n",
    "            else :\n",
    "                print(\"Unrecognized loss !\")\n",
    "\n",
    "            wandb.log({\"loss\": loss})\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += float(loss) * pred.numel()\n",
    "            total_examples += pred.numel()\n",
    "\n",
    "        score, val_loss = evaluate(config, val_loader, model, criterion, stopper_metric=config.stopper_metric, compute_all_metrics= True)\n",
    "        wandb.log({\"val_loss\": val_loss, f\"{config.stopper_metric}\": score})\n",
    "\n",
    "        train_loss = total_loss / total_examples\n",
    "        print(f\"Epoch: {epoch:03d}, Avg. Loss: {train_loss:.10f}\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # early_stopper(score)\n",
    "        # if early_stopper.early_stop:\n",
    "        #     print(\"Early stopping triggered at epoch\", epoch)\n",
    "        #     break\n",
    "\n",
    "    print(\"Training done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Which labels should be used ?\n",
    "# # Choices are : 'usual', 'rand_linsim', linsim', 'gaussian_noise', 'usual'.\n",
    "# labels_type = 'usual'\n",
    "\n",
    "# # How many epochs between 2 time-consuming evaluations ?\n",
    "# eval_period = 1\n",
    "\n",
    "# # Wandb\n",
    "# xp_name = 'GNN Baseline VS LinSim VS Noise With MSE'\n",
    "# run_name = f'{labels_type} labels with sigmoid_focal_loss'\n",
    "# print(xp_name,':',run_name)\n",
    "\n",
    "# run = wandb.init(project=xp_name, name = run_name)\n",
    "# config = wandb.config\n",
    "# config.labels_type = labels_type\n",
    "# config.val_ratio=0.1\n",
    "# config.homogeneous=False\n",
    "# config.scorelist_size=1000\n",
    "# config.split_ratio=0.8\n",
    "# config.val_ratio=0.1\n",
    "# config.test_ratio=0.1\n",
    "# config.num_neighbors=[70,55,13,89,85]\n",
    "# config.batch_size=1024\n",
    "# config.train_neg_sampling_ratio=224\n",
    "# config.epochs=epochs\n",
    "# config.disjoint_train_ratio=0.6\n",
    "# config.lr=0.0015308253347932983\n",
    "# config.stopper_metric= 'hit_at_10'\n",
    "# config.stopper_direction=\"maximize\"\n",
    "# config.stopper_patience=5\n",
    "# config.stopper_frequency=1\n",
    "# config.stopper_relative_delta=0.05\n",
    "# config.gamma=1.3\n",
    "# config.alpha=0.42680473078813763\n",
    "# config.gnn_layer='ResGatedGraphConv'\n",
    "# config.dropout=0.1\n",
    "# config.norm='DiffGroupNorm'\n",
    "# config.aggregation = 'min'\n",
    "# config.hidden_channels=115\n",
    "# config.num_layers=3\n",
    "# config.attention_heads=4\n",
    "# config.homogeneous = False\n",
    "# config.labels = {'head' : 'genes', 'relation' : 'gene_ontology', 'tail' : 'go'}\n",
    "\n",
    "# data = load_iric_data('/home/ebutz/ESL2024/data/full_iric/iric.csv', featureless=False)\n",
    "# data  = T.ToUndirected(merge=True)(data) # Convert the graph to an undirected graph. Creates reverse edges for each edge.\n",
    "# data = T.RemoveDuplicatedEdges()(data) # Remove duplicated edges\n",
    "# print(data)\n",
    "# print('data look valid : ',data.validate())\n",
    "\n",
    "# train_data, val_data, test_data = split_data(data, config)\n",
    "# train_loader, val_loader, test_loader = build_dataloaders(train_data, val_data, test_data, config)\n",
    "\n",
    "\n",
    "# gnn_layers = get_gnn_layers(config)\n",
    "# norm_layers = get_norm_layers(config, len(data.node_types))\n",
    "\n",
    "# model = Model(config, data, norm_layers, gnn_layers).to(device)\n",
    "\n",
    "# criterion = sigmoid_focal_loss\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "# early_stopper = EarlyStopper(frequency=config.stopper_frequency, patience=config.stopper_patience,\n",
    "#                              direction=config.stopper_direction, relative_delta=config.stopper_relative_delta)\n",
    "\n",
    "# train(config, train_loader, val_loader, model, criterion, optimizer, early_stopper, labels_type=config.labels_type, eval_period = eval_period)\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN Baseline VS LinSim VS Noise With MSE : rand_linsim labels and MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbutzelliot\u001b[0m (\u001b[33mesl2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ebutz/ESL2024/wandb/run-20240614_103915-bgjolb5z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/bgjolb5z' target=\"_blank\">rand_linsim labels and MSE</a></strong> to <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/bgjolb5z' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/bgjolb5z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebutz/ESL2024/code/utils/train_utils.py:184: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_links['source_node'] = df_links.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  genes={ x=[72335, 29] },\n",
      "  go={ x=[42979, 3] },\n",
      "  po={ x=[1662, 2] },\n",
      "  traito={ x=[1636, 1] },\n",
      "  prosite_profiles={ x=[627, 1] },\n",
      "  prosite_patterns={ x=[652, 1] },\n",
      "  superfamily={ x=[957, 1] },\n",
      "  panther={ x=[5971, 1] },\n",
      "  prints={ x=[420, 1] },\n",
      "  (genes, interacts_with, genes)={ edge_index=[2, 1120849] },\n",
      "  (genes, gene_ontology, go)={ edge_index=[2, 169248] },\n",
      "  (genes, trait_ontology, traito)={ edge_index=[2, 15080] },\n",
      "  (genes, plant_ontology, po)={ edge_index=[2, 6125] },\n",
      "  (genes, profile, prosite_profiles)={ edge_index=[2, 12239] },\n",
      "  (genes, pattern, prosite_patterns)={ edge_index=[2, 6677] },\n",
      "  (genes, family, superfamily)={ edge_index=[2, 20742] },\n",
      "  (genes, panther_id, panther)={ edge_index=[2, 25319] },\n",
      "  (genes, prints_id, prints)={ edge_index=[2, 4365] },\n",
      "  (go, is_a, go)={ edge_index=[2, 136436] },\n",
      "  (po, is_a, po)={ edge_index=[2, 3548] },\n",
      "  (traito, is_a, traito)={ edge_index=[2, 3770] },\n",
      "  (go, rev_gene_ontology, genes)={ edge_index=[2, 169248] },\n",
      "  (traito, rev_trait_ontology, genes)={ edge_index=[2, 15080] },\n",
      "  (po, rev_plant_ontology, genes)={ edge_index=[2, 6125] },\n",
      "  (prosite_profiles, rev_profile, genes)={ edge_index=[2, 12239] },\n",
      "  (prosite_patterns, rev_pattern, genes)={ edge_index=[2, 6677] },\n",
      "  (superfamily, rev_family, genes)={ edge_index=[2, 20742] },\n",
      "  (panther, rev_panther_id, genes)={ edge_index=[2, 25319] },\n",
      "  (prints, rev_prints_id, genes)={ edge_index=[2, 4365] }\n",
      ")\n",
      "data look valid :  True\n",
      "Function 'split_data' executed in 0.0125s\n",
      "Function 'build_dataloaders' executed in 0.1398s\n",
      "LOSS : MSELoss()\n",
      "XP name : rand_linsim labels and MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/80 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 69\u001b[0m\n\u001b[1;32m     64\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlr)\n\u001b[1;32m     66\u001b[0m early_stopper \u001b[38;5;241m=\u001b[39m EarlyStopper(frequency\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstopper_frequency, patience\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstopper_patience,\n\u001b[1;32m     67\u001b[0m                         direction\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstopper_direction, relative_delta\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstopper_relative_delta)\n\u001b[0;32m---> 69\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_period\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloss_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# evaluate(config,  val_loader, model, criterion, compute_all_metrics=False, loader_type='validation', stopper_metric='hit_at_10')\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# evaluate(config, test_loader, model, criterion, compute_all_metrics=False, loader_type='test'      , stopper_metric='hit_at_10')\u001b[39;00m\n\u001b[1;32m     78\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[5], line 168\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config, train_loader, val_loader, model, criterion, loss_name, optimizer, early_stopper, labels_type, eval_period, xp_name)\u001b[0m\n\u001b[1;32m    165\u001b[0m     lin_neg_samples\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    166\u001b[0m     pos_samples\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 168\u001b[0m     ground_truth \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlin_neg_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     ground_truth\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussian_noise\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# Add gaussian noise to pos_samples to simulate noisy labels. Added noise must be negative and not exceed 1.\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10):\n",
    "      # Which labels should be used ?\n",
    "      # Choices are : 'usual', 'rand_linsim', linsim', 'gaussian_noise', 'usual'.\n",
    "      labels_type = 'rand_linsim'\n",
    "      loss_name = 'MSE'\n",
    "\n",
    "      # How many epochs between 2 time-consuming evaluations ?\n",
    "      eval_period = 1\n",
    "\n",
    "      # Wandb\n",
    "      xp_name = 'GNN Baseline VS LinSim VS Noise With MSE'\n",
    "      run_name = f'{labels_type} labels and {loss_name}'\n",
    "      print(xp_name,':',run_name)\n",
    "\n",
    "      run = wandb.init(project=xp_name, name = run_name)\n",
    "      config = wandb.config\n",
    "      config.labels_type = labels_type\n",
    "      config.val_ratio=0.1\n",
    "      config.homogeneous=False\n",
    "      config.scorelist_size=1000\n",
    "      config.split_ratio=0.8\n",
    "      config.val_ratio=0.1\n",
    "      config.test_ratio=0.1\n",
    "      config.num_neighbors=[70,55,13,89,85]\n",
    "      config.batch_size=1024\n",
    "      config.train_neg_sampling_ratio=224\n",
    "      config.epochs=epochs\n",
    "      config.disjoint_train_ratio=0.6\n",
    "      config.lr=0.0015308253347932983\n",
    "      config.stopper_metric= 'hit_at_10'\n",
    "      config.stopper_direction=\"maximize\"\n",
    "      config.stopper_patience=5\n",
    "      config.stopper_frequency=1\n",
    "      config.stopper_relative_delta=0.05\n",
    "      config.gamma=1.3\n",
    "      config.alpha=0.42680473078813763\n",
    "      config.gnn_layer='ResGatedGraphConv'\n",
    "      config.dropout=0.1\n",
    "      config.norm='DiffGroupNorm'\n",
    "      config.aggregation = 'min'\n",
    "      config.hidden_channels=115\n",
    "      config.num_layers=3\n",
    "      config.attention_heads=4\n",
    "      config.homogeneous = False\n",
    "      config.labels = {'head' : 'genes', 'relation' : 'gene_ontology', 'tail' : 'go'}\n",
    "\n",
    "      data = load_iric_data('/home/ebutz/ESL2024/data/full_iric/iric.csv', featureless=False)\n",
    "      data  = T.ToUndirected(merge=True)(data) # Convert the graph to an undirected graph. Creates reverse edges for each edge.\n",
    "      data = T.RemoveDuplicatedEdges()(data) # Remove duplicated edges\n",
    "      print(data)\n",
    "      print('data look valid : ',data.validate())\n",
    "\n",
    "      train_data, val_data, test_data = split_data(data, config)\n",
    "      train_loader, val_loader, test_loader = build_dataloaders(train_data, val_data, test_data, config)\n",
    "\n",
    "\n",
    "      gnn_layers = get_gnn_layers(config)\n",
    "      norm_layers = get_norm_layers(config, len(data.node_types))\n",
    "\n",
    "      model = Model(config, data, norm_layers, gnn_layers).to(device)\n",
    "\n",
    "      criterion = torch.nn.MSELoss()\n",
    "\n",
    "      optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "      early_stopper = EarlyStopper(frequency=config.stopper_frequency, patience=config.stopper_patience,\n",
    "                              direction=config.stopper_direction, relative_delta=config.stopper_relative_delta)\n",
    "\n",
    "      train(config = config, train_loader = train_loader, val_loader =  val_loader, model = model,\n",
    "            criterion = criterion, optimizer = optimizer, early_stopper = None, eval_period = 0, xp_name=run_name,\n",
    "            loss_name=loss_name, labels_type=config.labels_type)\n",
    "\n",
    "\n",
    "      # evaluate(config,  val_loader, model, criterion, compute_all_metrics=False, loader_type='validation', stopper_metric='hit_at_10')\n",
    "      # evaluate(config, test_loader, model, criterion, compute_all_metrics=False, loader_type='test'      , stopper_metric='hit_at_10')\n",
    "\n",
    "\n",
    "      wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN Baseline VS LinSim VS Noise With MSE : linsim labels and MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbutzelliot\u001b[0m (\u001b[33mesl2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ebutz/ESL2024/wandb/run-20240613_120313-8gj7z2vi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/8gj7z2vi' target=\"_blank\">linsim labels and MSE</a></strong> to <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/8gj7z2vi' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/8gj7z2vi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebutz/ESL2024/code/utils/train_utils.py:184: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_links['source_node'] = df_links.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  genes={ x=[72335, 29] },\n",
      "  go={ x=[42979, 3] },\n",
      "  po={ x=[1662, 2] },\n",
      "  traito={ x=[1636, 1] },\n",
      "  prosite_profiles={ x=[627, 1] },\n",
      "  prosite_patterns={ x=[652, 1] },\n",
      "  superfamily={ x=[957, 1] },\n",
      "  panther={ x=[5971, 1] },\n",
      "  prints={ x=[420, 1] },\n",
      "  (genes, interacts_with, genes)={ edge_index=[2, 1120849] },\n",
      "  (genes, gene_ontology, go)={ edge_index=[2, 169248] },\n",
      "  (genes, trait_ontology, traito)={ edge_index=[2, 15080] },\n",
      "  (genes, plant_ontology, po)={ edge_index=[2, 6125] },\n",
      "  (genes, profile, prosite_profiles)={ edge_index=[2, 12239] },\n",
      "  (genes, pattern, prosite_patterns)={ edge_index=[2, 6677] },\n",
      "  (genes, family, superfamily)={ edge_index=[2, 20742] },\n",
      "  (genes, panther_id, panther)={ edge_index=[2, 25319] },\n",
      "  (genes, prints_id, prints)={ edge_index=[2, 4365] },\n",
      "  (go, is_a, go)={ edge_index=[2, 136436] },\n",
      "  (po, is_a, po)={ edge_index=[2, 3548] },\n",
      "  (traito, is_a, traito)={ edge_index=[2, 3770] },\n",
      "  (go, rev_gene_ontology, genes)={ edge_index=[2, 169248] },\n",
      "  (traito, rev_trait_ontology, genes)={ edge_index=[2, 15080] },\n",
      "  (po, rev_plant_ontology, genes)={ edge_index=[2, 6125] },\n",
      "  (prosite_profiles, rev_profile, genes)={ edge_index=[2, 12239] },\n",
      "  (prosite_patterns, rev_pattern, genes)={ edge_index=[2, 6677] },\n",
      "  (superfamily, rev_family, genes)={ edge_index=[2, 20742] },\n",
      "  (panther, rev_panther_id, genes)={ edge_index=[2, 25319] },\n",
      "  (prints, rev_prints_id, genes)={ edge_index=[2, 4365] }\n",
      ")\n",
      "data look valid :  True\n",
      "Function 'split_data' executed in 0.0133s\n",
      "Function 'build_dataloaders' executed in 0.1411s\n",
      "LOSS : MSELoss()\n",
      "XP name : linsim labels and MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:27<00:00,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Avg. Loss: 0.0211222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:28<00:00,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Avg. Loss: 0.0205074655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:31<00:00,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Avg. Loss: 0.0206860824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:35<00:00,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Avg. Loss: 0.0207604277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:30<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n",
      "Epoch: 004, Avg. Loss: 0.0206575033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:37<00:00,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Avg. Loss: 0.0207535970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:30<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n",
      "Epoch: 006, Avg. Loss: 0.0207445497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:25<00:00,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Avg. Loss: 0.0206865573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:25<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n",
      "Epoch: 008, Avg. Loss: 0.0207095660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:34<00:00,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Avg. Loss: 0.0208395128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:29<00:00,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Avg. Loss: 0.0204858034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:26<00:00,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Avg. Loss: 0.0208261595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:28<00:00,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Avg. Loss: 0.0206224070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:25<00:00,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Avg. Loss: 0.0205531086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 80/80 [05:23<00:00,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Avg. Loss: 0.0206065132\n",
      "Training done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>hit_at_10</td><td>▁▄▂▄▅▆▄█▅▆▇▇▇▇█</td></tr><tr><td>loss</td><td>█▄▂▇▇▄▄▅▂▃▃▁▂▇▂▆▃▅▄▃▄█▃▃▆▂▄▅▃██▄▂▆▂▃▃▆▆▄</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validationMRR</td><td>▁▄▂▄▅▆▄█▅▆▇▇▇▇█</td></tr><tr><td>validationhit_at_1</td><td>▁▄▂▄▅▆▃█▅▇▇▇▇▇█</td></tr><tr><td>validationhit_at_10</td><td>▁▃▃▁▂▄▁▃▃▃▃▅█▆▇</td></tr><tr><td>validationhit_at_3</td><td>▁▃▃▄▄▆▄▇▆▆▇▆█▇█</td></tr><tr><td>validationhit_at_5</td><td>▂▂▁▂▂▄▃▆▆▄▅▆█▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>hit_at_10</td><td>0.42724</td></tr><tr><td>loss</td><td>0.0207</td></tr><tr><td>val_loss</td><td>1</td></tr><tr><td>validationMRR</td><td>0.42724</td></tr><tr><td>validationhit_at_1</td><td>0.28853</td></tr><tr><td>validationhit_at_10</td><td>0.72745</td></tr><tr><td>validationhit_at_3</td><td>0.48357</td></tr><tr><td>validationhit_at_5</td><td>0.587</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">linsim labels and MSE</strong> at: <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/8gj7z2vi' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/8gj7z2vi</a><br/> View project at: <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240613_120313-8gj7z2vi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Which labels should be used ?\n",
    "# Choices are : 'usual', 'rand_linsim', linsim', 'gaussian_noise', 'usual'.\n",
    "labels_type = 'linsim'\n",
    "loss_name = 'MSE'\n",
    "\n",
    "# How many epochs between 2 time-consuming evaluations ?\n",
    "\n",
    "# Wandb\n",
    "xp_name = 'GNN Baseline VS LinSim VS Noise With MSE'\n",
    "run_name = f'{labels_type} labels and {loss_name}'\n",
    "print(xp_name,':',run_name)\n",
    "\n",
    "run = wandb.init(project=xp_name, name = run_name)\n",
    "config = wandb.config\n",
    "config.labels_type = labels_type\n",
    "config.val_ratio=0.1\n",
    "config.homogeneous=False\n",
    "config.scorelist_size=1000\n",
    "config.split_ratio=0.8\n",
    "config.val_ratio=0.1\n",
    "config.test_ratio=0.1\n",
    "config.num_neighbors=[70,55,13,89,85]\n",
    "config.batch_size=1024\n",
    "config.train_neg_sampling_ratio=224\n",
    "config.epochs=epochs\n",
    "config.disjoint_train_ratio=0.6\n",
    "config.lr=0.0015308253347932983\n",
    "config.stopper_metric= 'hit_at_10'\n",
    "config.stopper_direction=\"maximize\"\n",
    "config.stopper_patience=5\n",
    "config.stopper_frequency=1\n",
    "config.stopper_relative_delta=0.05\n",
    "config.gamma=1.3\n",
    "config.alpha=0.42680473078813763\n",
    "config.gnn_layer='ResGatedGraphConv'\n",
    "config.dropout=0.1\n",
    "config.norm='DiffGroupNorm'\n",
    "config.aggregation = 'min'\n",
    "config.hidden_channels=115\n",
    "config.num_layers=3\n",
    "config.attention_heads=4\n",
    "config.homogeneous = False\n",
    "config.labels = {'head' : 'genes', 'relation' : 'gene_ontology', 'tail' : 'go'}\n",
    "\n",
    "data = load_iric_data('/home/ebutz/ESL2024/data/full_iric/iric.csv', featureless=False)\n",
    "data  = T.ToUndirected(merge=True)(data) # Convert the graph to an undirected graph. Creates reverse edges for each edge.\n",
    "data = T.RemoveDuplicatedEdges()(data) # Remove duplicated edges\n",
    "print(data)\n",
    "print('data look valid : ',data.validate())\n",
    "\n",
    "train_data, val_data, test_data = split_data(data, config)\n",
    "train_loader, val_loader, test_loader = build_dataloaders(train_data, val_data, test_data, config)\n",
    "\n",
    "\n",
    "gnn_layers = get_gnn_layers(config)\n",
    "norm_layers = get_norm_layers(config, len(data.node_types))\n",
    "\n",
    "model = Model(config, data, norm_layers, gnn_layers).to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "early_stopper = EarlyStopper(frequency=config.stopper_frequency, patience=config.stopper_patience,\n",
    "                             direction=config.stopper_direction, relative_delta=config.stopper_relative_delta)\n",
    "\n",
    "train(config = config, train_loader = train_loader, val_loader =  val_loader, model = model,\n",
    "      criterion = criterion, optimizer = optimizer, early_stopper = None, eval_period = 0, xp_name=run_name,\n",
    "      loss_name=loss_name, labels_type=config.labels_type)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN Baseline VS LinSim VS Noise With MSE : rand_linsim labels and MSE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gg0s4kn2) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">usual labels and sigmoid focal</strong> at: <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/gg0s4kn2' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/gg0s4kn2</a><br/> View project at: <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240613_143958-gg0s4kn2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:gg0s4kn2). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ebutz/ESL2024/wandb/run-20240613_144039-ru954kbe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/ru954kbe' target=\"_blank\">rand_linsim labels and MSE</a></strong> to <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/ru954kbe' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/ru954kbe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebutz/ESL2024/code/utils/train_utils.py:184: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_links['source_node'] = df_links.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  genes={ x=[72335, 29] },\n",
      "  go={ x=[42979, 3] },\n",
      "  po={ x=[1662, 2] },\n",
      "  traito={ x=[1636, 1] },\n",
      "  prosite_profiles={ x=[627, 1] },\n",
      "  prosite_patterns={ x=[652, 1] },\n",
      "  superfamily={ x=[957, 1] },\n",
      "  panther={ x=[5971, 1] },\n",
      "  prints={ x=[420, 1] },\n",
      "  (genes, interacts_with, genes)={ edge_index=[2, 1120849] },\n",
      "  (genes, gene_ontology, go)={ edge_index=[2, 169248] },\n",
      "  (genes, trait_ontology, traito)={ edge_index=[2, 15080] },\n",
      "  (genes, plant_ontology, po)={ edge_index=[2, 6125] },\n",
      "  (genes, profile, prosite_profiles)={ edge_index=[2, 12239] },\n",
      "  (genes, pattern, prosite_patterns)={ edge_index=[2, 6677] },\n",
      "  (genes, family, superfamily)={ edge_index=[2, 20742] },\n",
      "  (genes, panther_id, panther)={ edge_index=[2, 25319] },\n",
      "  (genes, prints_id, prints)={ edge_index=[2, 4365] },\n",
      "  (go, is_a, go)={ edge_index=[2, 136436] },\n",
      "  (po, is_a, po)={ edge_index=[2, 3548] },\n",
      "  (traito, is_a, traito)={ edge_index=[2, 3770] },\n",
      "  (go, rev_gene_ontology, genes)={ edge_index=[2, 169248] },\n",
      "  (traito, rev_trait_ontology, genes)={ edge_index=[2, 15080] },\n",
      "  (po, rev_plant_ontology, genes)={ edge_index=[2, 6125] },\n",
      "  (prosite_profiles, rev_profile, genes)={ edge_index=[2, 12239] },\n",
      "  (prosite_patterns, rev_pattern, genes)={ edge_index=[2, 6677] },\n",
      "  (superfamily, rev_family, genes)={ edge_index=[2, 20742] },\n",
      "  (panther, rev_panther_id, genes)={ edge_index=[2, 25319] },\n",
      "  (prints, rev_prints_id, genes)={ edge_index=[2, 4365] }\n",
      ")\n",
      "data look valid :  True\n",
      "Function 'split_data' executed in 0.0114s\n",
      "Function 'build_dataloaders' executed in 0.1362s\n",
      "LOSS : MSELoss()\n",
      "XP name : rand_linsim labels and MSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/80 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 67\u001b[0m\n\u001b[1;32m     62\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlr)\n\u001b[1;32m     64\u001b[0m early_stopper \u001b[38;5;241m=\u001b[39m EarlyStopper(frequency\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstopper_frequency, patience\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstopper_patience,\n\u001b[1;32m     65\u001b[0m                              direction\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstopper_direction, relative_delta\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mstopper_relative_delta)\n\u001b[0;32m---> 67\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_period\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloss_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[2], line 168\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config, train_loader, val_loader, model, criterion, loss_name, optimizer, early_stopper, labels_type, eval_period, xp_name)\u001b[0m\n\u001b[1;32m    165\u001b[0m     lin_neg_samples\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    166\u001b[0m     pos_samples\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 168\u001b[0m     ground_truth \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlin_neg_samples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussian_noise\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# Add gaussian noise to pos_samples to simulate noisy labels. Added noise must be negative and not exceed 1.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     ground_truth \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnormal(mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ground_truth),), device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)"
     ]
    }
   ],
   "source": [
    "# Which labels should be used ?\n",
    "# Choices are : 'usual', 'rand_linsim', linsim', 'gaussian_noise', 'usual'.\n",
    "labels_type = 'rand_linsim'\n",
    "loss_name = 'MSE'\n",
    "\n",
    "# How many epochs between 2 time-consuming evaluations ?\n",
    "\n",
    "# Wandb\n",
    "xp_name = 'GNN Baseline VS LinSim VS Noise With MSE'\n",
    "run_name = f'{labels_type} labels and {loss_name}'\n",
    "print(xp_name,':',run_name)\n",
    "\n",
    "run = wandb.init(project=xp_name, name = run_name)\n",
    "config = wandb.config\n",
    "config.labels_type = labels_type\n",
    "config.val_ratio=0.1\n",
    "config.homogeneous=False\n",
    "config.scorelist_size=1000\n",
    "config.split_ratio=0.8\n",
    "config.val_ratio=0.1\n",
    "config.test_ratio=0.1\n",
    "config.num_neighbors=[70,55,13,89,85]\n",
    "config.batch_size=1024\n",
    "config.train_neg_sampling_ratio=224\n",
    "config.epochs=epochs\n",
    "config.disjoint_train_ratio=0.6\n",
    "config.lr=0.0015308253347932983\n",
    "config.stopper_metric= 'hit_at_10'\n",
    "config.stopper_direction=\"maximize\"\n",
    "config.stopper_patience=5\n",
    "config.stopper_frequency=1\n",
    "config.stopper_relative_delta=0.05\n",
    "config.gamma=1.3\n",
    "config.alpha=0.42680473078813763\n",
    "config.gnn_layer='ResGatedGraphConv'\n",
    "config.dropout=0.1\n",
    "config.norm='DiffGroupNorm'\n",
    "config.aggregation = 'min'\n",
    "config.hidden_channels=115\n",
    "config.num_layers=3\n",
    "config.attention_heads=4\n",
    "config.homogeneous = False\n",
    "config.labels = {'head' : 'genes', 'relation' : 'gene_ontology', 'tail' : 'go'}\n",
    "\n",
    "data = load_iric_data('/home/ebutz/ESL2024/data/full_iric/iric.csv', featureless=False)\n",
    "data  = T.ToUndirected(merge=True)(data) # Convert the graph to an undirected graph. Creates reverse edges for each edge.\n",
    "data = T.RemoveDuplicatedEdges()(data) # Remove duplicated edges\n",
    "print(data)\n",
    "print('data look valid : ',data.validate())\n",
    "\n",
    "train_data, val_data, test_data = split_data(data, config)\n",
    "train_loader, val_loader, test_loader = build_dataloaders(train_data, val_data, test_data, config)\n",
    "\n",
    "\n",
    "gnn_layers = get_gnn_layers(config)\n",
    "norm_layers = get_norm_layers(config, len(data.node_types))\n",
    "\n",
    "model = Model(config, data, norm_layers, gnn_layers).to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "early_stopper = EarlyStopper(frequency=config.stopper_frequency, patience=config.stopper_patience,\n",
    "                             direction=config.stopper_direction, relative_delta=config.stopper_relative_delta)\n",
    "\n",
    "train(config = config, train_loader = train_loader, val_loader =  val_loader, model = model,\n",
    "      criterion = criterion, optimizer = optimizer, early_stopper = None, eval_period = 0, xp_name=run_name,\n",
    "      loss_name=loss_name, labels_type=config.labels_type)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN Baseline VS LinSim VS Noise With MSE : usual labels and sigmoid focal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1w39o7x0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>hit_at_10</td><td>▁▅▅▇▅▆█▆</td></tr><tr><td>loss</td><td>█▄▃▂▂▃▁▃▂▂▁▃▂▂▂▂▂▃▂▂▂▁▂▃▂▁▂▁▂▂▁▂▂▂▁▂▃▃▁▂</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>validationMRR</td><td>▁▅▅▇▅▆█▆</td></tr><tr><td>validationhit_at_1</td><td>▁▄▅▆▄▆█▆</td></tr><tr><td>validationhit_at_10</td><td>▁▅▃▇▆▇▆█</td></tr><tr><td>validationhit_at_3</td><td>▁▆▆▇▆▆█▇</td></tr><tr><td>validationhit_at_5</td><td>▁█▅▇▆▅█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>hit_at_10</td><td>0.42081</td></tr><tr><td>loss</td><td>0.14062</td></tr><tr><td>val_loss</td><td>1</td></tr><tr><td>validationMRR</td><td>0.42081</td></tr><tr><td>validationhit_at_1</td><td>0.28055</td></tr><tr><td>validationhit_at_10</td><td>0.72825</td></tr><tr><td>validationhit_at_3</td><td>0.4771</td></tr><tr><td>validationhit_at_5</td><td>0.58399</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">usual labels and sigmoid focal</strong> at: <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/1w39o7x0' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/1w39o7x0</a><br/> View project at: <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240613_141526-1w39o7x0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1w39o7x0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ebutz/ESL2024/wandb/run-20240613_143958-gg0s4kn2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/gg0s4kn2' target=\"_blank\">usual labels and sigmoid focal</a></strong> to <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/gg0s4kn2' target=\"_blank\">https://wandb.ai/esl2024/GNN%20Baseline%20VS%20LinSim%20VS%20Noise%20With%20MSE/runs/gg0s4kn2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m config\u001b[38;5;241m.\u001b[39mhomogeneous \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     42\u001b[0m config\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelation\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgene_ontology\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtail\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgo\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m---> 44\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mload_iric_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/ebutz/ESL2024/data/full_iric/iric.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatureless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m data  \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mToUndirected(merge\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(data) \u001b[38;5;66;03m# Convert the graph to an undirected graph. Creates reverse edges for each edge.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m data \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mRemoveDuplicatedEdges()(data) \u001b[38;5;66;03m# Remove duplicated edges\u001b[39;00m\n",
      "File \u001b[0;32m~/ESL2024/code/utils/train_utils.py:137\u001b[0m, in \u001b[0;36mload_iric_data\u001b[0;34m(path, featureless)\u001b[0m\n\u001b[1;32m    104\u001b[0m     features \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m\"\u001b[39m: df[df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(nodelist[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m\"\u001b[39m])][IricGene\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mvalue],\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraito\u001b[39m\u001b[38;5;124m\"\u001b[39m: df[df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39misin(nodelist[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraito\u001b[39m\u001b[38;5;124m\"\u001b[39m])][IricTO\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mvalue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuperfamily\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    114\u001b[0m     }\n\u001b[1;32m    116\u001b[0m     genes_x, genes_mapping \u001b[38;5;241m=\u001b[39m load_node_matrix(\n\u001b[1;32m    117\u001b[0m         nodelist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m], features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenes\u001b[39m\u001b[38;5;124m'\u001b[39m], encoders\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    118\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbiotype\u001b[39m\u001b[38;5;124m'\u001b[39m: OneHotEncoder(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[38;5;66;03m# Explanation: SentenceEncoder(),\u001b[39;00m\n\u001b[1;32m    135\u001b[0m         })\n\u001b[0;32m--> 137\u001b[0m     go_x, go_mapping \u001b[38;5;241m=\u001b[39m \u001b[43mload_node_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodelist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnamespace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# 'definition': SentenceEncoder(),\u001b[39;49;00m\n\u001b[1;32m    141\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# 'name': SentenceEncoder(),\u001b[39;49;00m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     po_x, po_mapping \u001b[38;5;241m=\u001b[39m load_node_matrix(\n\u001b[1;32m    145\u001b[0m         nodelist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpo\u001b[39m\u001b[38;5;124m'\u001b[39m], features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpo\u001b[39m\u001b[38;5;124m'\u001b[39m], encoders\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    146\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace\u001b[39m\u001b[38;5;124m'\u001b[39m: OneHotEncoder(),\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;66;03m# 'definition': SentenceEncoder(),\u001b[39;00m\n\u001b[1;32m    148\u001b[0m             \u001b[38;5;66;03m# 'name': SentenceEncoder(),\u001b[39;00m\n\u001b[1;32m    149\u001b[0m         })\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/ESL2024/code/utils/data_utils.py:141\u001b[0m, in \u001b[0;36mload_node_matrix\u001b[0;34m(nodelist, node_features, encoders, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([])\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoders \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     xs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodelist\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mencoders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    142\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(xs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, mapping\n",
      "File \u001b[0;32m~/ESL2024/code/utils/data_utils.py:141\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([])\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoders \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     xs \u001b[38;5;241m=\u001b[39m [\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnodelist\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col, encoder \u001b[38;5;129;01min\u001b[39;00m encoders\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m    142\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(xs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, mapping\n",
      "File \u001b[0;32m~/ESL2024/code/utils/train_utils.py:702\u001b[0m, in \u001b[0;36mOneHotEncoder.__call__\u001b[0;34m(self, df, nodelist)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Populate the tensor with 1s based on the mapping\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df):\n\u001b[0;32m--> 702\u001b[0m     x[i, mapping[category]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Which labels should be used ?\n",
    "# Choices are : 'usual', 'rand_linsim', linsim', 'gaussian_noise', 'usual'.\n",
    "labels_type = 'usual'\n",
    "loss_name = 'sigmoid focal'\n",
    "criterion = sigmoid_focal_loss\n",
    "\n",
    "# Wandb\n",
    "xp_name = 'GNN Baseline VS LinSim VS Noise With MSE'\n",
    "run_name = f'{labels_type} labels and {loss_name}'\n",
    "print(xp_name,':',run_name)\n",
    "\n",
    "run = wandb.init(project=xp_name, name = run_name)\n",
    "config = wandb.config\n",
    "config.labels_type = labels_type\n",
    "config.val_ratio=0.1\n",
    "config.homogeneous=False\n",
    "config.scorelist_size=1000\n",
    "config.split_ratio=0.8\n",
    "config.val_ratio=0.1\n",
    "config.test_ratio=0.1\n",
    "config.num_neighbors=[70,55,13,89,85]\n",
    "config.batch_size=1024\n",
    "config.train_neg_sampling_ratio=224\n",
    "config.epochs=epochs\n",
    "config.disjoint_train_ratio=0.6\n",
    "config.lr=0.0015308253347932983\n",
    "config.stopper_metric= 'hit_at_10'\n",
    "config.stopper_direction=\"maximize\"\n",
    "config.stopper_patience=5\n",
    "config.stopper_frequency=1\n",
    "config.stopper_relative_delta=0.05\n",
    "config.gamma=1.3\n",
    "config.alpha=0.42680473078813763\n",
    "config.gnn_layer='ResGatedGraphConv'\n",
    "config.dropout=0.1\n",
    "config.norm='DiffGroupNorm'\n",
    "config.aggregation = 'min'\n",
    "config.hidden_channels=115\n",
    "config.num_layers=3\n",
    "config.attention_heads=4\n",
    "config.homogeneous = False\n",
    "config.labels = {'head' : 'genes', 'relation' : 'gene_ontology', 'tail' : 'go'}\n",
    "\n",
    "data = load_iric_data('/home/ebutz/ESL2024/data/full_iric/iric.csv', featureless=False)\n",
    "data  = T.ToUndirected(merge=True)(data) # Convert the graph to an undirected graph. Creates reverse edges for each edge.\n",
    "data = T.RemoveDuplicatedEdges()(data) # Remove duplicated edges\n",
    "print(data)\n",
    "print('data look valid : ',data.validate())\n",
    "\n",
    "train_data, val_data, test_data = split_data(data, config)\n",
    "train_loader, val_loader, test_loader = build_dataloaders(train_data, val_data, test_data, config)\n",
    "\n",
    "\n",
    "gnn_layers = get_gnn_layers(config)\n",
    "norm_layers = get_norm_layers(config, len(data.node_types))\n",
    "\n",
    "model = Model(config, data, norm_layers, gnn_layers).to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "early_stopper = EarlyStopper(frequency=config.stopper_frequency, patience=config.stopper_patience,\n",
    "                             direction=config.stopper_direction, relative_delta=config.stopper_relative_delta)\n",
    "\n",
    "train(config = config, train_loader = train_loader, val_loader =  val_loader, model = model,\n",
    "      criterion = criterion, optimizer = optimizer, early_stopper = None, eval_period = 0, xp_name=run_name,\n",
    "      loss_name=loss_name , labels_type=config.labels_type)\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
