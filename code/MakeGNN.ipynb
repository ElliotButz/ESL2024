{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iric\n",
    "iric_path = '/home/ebutz/ESL2024/data/full_iric/iric.csv'\n",
    "mapped_iric_path  = '/home/ebutz/ESL2024/data/full_iric/altailed_mapped_iric.pickle'\n",
    "altails_dict_path = '/home/ebutz/ESL2024/data/full_iric/altail_iric_DICT.pickle'\n",
    "check_dicts = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imports...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebutz/miniconda3/envs/pyg2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nImports...\")\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/ebutz/ESL2024/code/utils' )\n",
    "from play_with_complex import *\n",
    "from data_utils import *\n",
    "from train_utils import *\n",
    "from model_utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import optuna\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.sampler import NegativeSampling\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import ComplEx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nxontology.imports import from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'homogeneous': False,\n",
       " 'scorelist_size': 1000,\n",
       " 'split_ratio': 0.8,\n",
       " 'val_ratio': 0.1,\n",
       " 'test_ratio': 0.1,\n",
       " 'num_neighbors': [70, 55, 13, 89, 85],\n",
       " 'batch_size': 1024,\n",
       " 'train_neg_sampling_ratio': 224,\n",
       " 'epochs': 18,\n",
       " 'disjoint_train_ratio': 0.6,\n",
       " 'lr': 0.0015308253347932983,\n",
       " 'stopper_metric': 'mrr',\n",
       " 'stopper_direction': 'maximize',\n",
       " 'stopper_patience': 5,\n",
       " 'stopper_frequency': 1,\n",
       " 'stopper_relative_delta': 0.05,\n",
       " 'gamma': 1.3,\n",
       " 'alpha': 0.42680473078813763,\n",
       " 'gnn_layer': 'ResGatedGraphConv',\n",
       " 'dropout': 0.1,\n",
       " 'norm': 'DiffGroupNorm',\n",
       " 'aggregation': 'min',\n",
       " 'hidden_channels': 115,\n",
       " 'num_layers': 3,\n",
       " 'attention_heads': 4}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'homogeneous': False, 'scorelist_size': 1000, 'split_ratio': 0.8, 'val_ratio': 0.1, 'test_ratio': 0.1,\n",
    " 'num_neighbors': [70, 55, 13, 89, 85], 'batch_size': 1024, 'train_neg_sampling_ratio': 224, 'epochs': 18,\n",
    " 'disjoint_train_ratio': 0.6, 'lr': 0.0015308253347932983, 'stopper_metric': 'mrr', 'stopper_direction': 'maximize',\n",
    " 'stopper_patience': 5, 'stopper_frequency': 1, 'stopper_relative_delta': 0.05, 'gamma': 1.3, 'alpha': 0.42680473078813763, 'gnn_layer': 'ResGatedGraphConv',\n",
    " 'dropout': 0.1, 'norm': 'DiffGroupNorm', 'aggregation': 'min', 'hidden_channels': 115, 'num_layers': 3, 'attention_heads': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbutzelliot\u001b[0m (\u001b[33mesl2024\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ebutz/ESL2024/code/wandb/run-20240424_154121-fr3eqe6z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esl2024/ESL2024-code/runs/fr3eqe6z' target=\"_blank\">cosmic-terrain-55</a></strong> to <a href='https://wandb.ai/esl2024/ESL2024-code' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esl2024/ESL2024-code' target=\"_blank\">https://wandb.ai/esl2024/ESL2024-code</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esl2024/ESL2024-code/runs/fr3eqe6z' target=\"_blank\">https://wandb.ai/esl2024/ESL2024-code/runs/fr3eqe6z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'wandb.sdk.wandb_config.Config'>\n",
      "False\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# config = {'val_ratio': 0.1,'homogeneous': False, 'scorelist_size': 1000, 'split_ratio': 0.8,'val_ratio': 0.1, 'test_ratio': 0.1, 'num_neighbors': [70, 55, 13, 89, 85],\n",
    "#           'batch_size': 1024, 'train_neg_sampling_ratio': 224, 'epochs': 18, 'disjoint_train_ratio': 0.6,\n",
    "#           'lr': 0.0015308253347932983, 'stopper_metric': 'mrr', 'stopper_direction': 'maximize',\n",
    "#           'stopper_patience': 5, 'stopper_frequency': 1, 'stopper_relative_delta': 0.05, 'gamma': 1.3,\n",
    "#           'alpha': 0.42680473078813763, 'gnn_layer': 'ResGatedGraphConv', 'dropout': 0.1,\n",
    "#           'norm': 'DiffGroupNorm', 'aggregation': 'min', 'hidden_channels': 115, 'num_layers': 3, 'attention_heads': 4}\n",
    "\n",
    "# run = wandb.init(config = config)\n",
    "run = wandb.init()\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "config.val_ratio=0.1\n",
    "config.homogeneous=False\n",
    "config.scorelist_size=1000\n",
    "config.split_ratio=0.8\n",
    "config.val_ratio=0.1\n",
    "config.test_ratio=0.1\n",
    "config.num_neighbors=[70,55,13,89,85]\n",
    "config.batch_size=1024\n",
    "config.train_neg_sampling_ratio=224\n",
    "config.epochs=18\n",
    "config.disjoint_train_ratio=0.6\n",
    "config.lr=0.0015308253347932983\n",
    "config.stopper_metric= 'mrr'\n",
    "config.stopper_direction=\"maximize\"\n",
    "config.stopper_patience=5\n",
    "config.stopper_frequency=1\n",
    "config.stopper_relative_delta=0.05\n",
    "config.gamma=1.3\n",
    "config.alpha=0.42680473078813763\n",
    "config.gnn_layer='ResGatedGraphConv'\n",
    "config.dropout=0.1\n",
    "config.norm='DiffGroupNorm'\n",
    "config.aggregation = 'min'\n",
    "config.hidden_channels=115\n",
    "config.num_layers=3\n",
    "config.attention_heads=4\n",
    "config.homogeneous = False\n",
    "config.labels = {'head' : 'genes', 'relation' : 'gene_ontology', 'tail' : 'go'}\n",
    "\n",
    "print(type(wandb.config))\n",
    "print(config.homogeneous)\n",
    "print(config.val_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9504/2580875774.py:1: DtypeWarning: Columns (1,2,3,4,6,7,8,9,10,11,12,13,14,15,18,20,21,22,23,24,25,26,27,28,29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(iric_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>definition</th>\n",
       "      <th>is_a</th>\n",
       "      <th>name</th>\n",
       "      <th>namespace</th>\n",
       "      <th>Annotation score</th>\n",
       "      <th>Gene Ontology</th>\n",
       "      <th>Genomic Sequence</th>\n",
       "      <th>InterPro:description</th>\n",
       "      <th>PANTHER</th>\n",
       "      <th>...</th>\n",
       "      <th>Gene Name Synonyms</th>\n",
       "      <th>Prosite_patterns</th>\n",
       "      <th>Trait Class</th>\n",
       "      <th>Trait Ontology</th>\n",
       "      <th>ncoils</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Family</th>\n",
       "      <th>PRINTS</th>\n",
       "      <th>Plant Ontology</th>\n",
       "      <th>Allele</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO:0000001</td>\n",
       "      <td>The distribution of mitochondria, including th...</td>\n",
       "      <td>GO:0048311|GO:0048308</td>\n",
       "      <td>mitochondrion inheritance</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>The maintenance of the structure and integrity...</td>\n",
       "      <td>GO:0007005</td>\n",
       "      <td>mitochondrial genome maintenance</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO:0000003</td>\n",
       "      <td>The production of new individuals that contain...</td>\n",
       "      <td>GO:0008150</td>\n",
       "      <td>reproduction</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0000006</td>\n",
       "      <td>Enables the transfer of zinc ions (Zn2+) from ...</td>\n",
       "      <td>GO:0005385</td>\n",
       "      <td>high-affinity zinc transmembrane transporter a...</td>\n",
       "      <td>molecular_function</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO:0000007</td>\n",
       "      <td>Enables the transfer of a solute or solutes fr...</td>\n",
       "      <td>GO:0005385</td>\n",
       "      <td>low-affinity zinc ion transmembrane transporte...</td>\n",
       "      <td>molecular_function</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118388</th>\n",
       "      <td>OsNippo12g261100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GCTAGCCGGCGCCGCCCCGACCGTTGCCGTCGCTCGCCGTGTGCTC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118389</th>\n",
       "      <td>OsNippo12g261150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ACTAGCTTATCAGGGGAGCCTTGATGCCGAGAGACATGTGGATTCG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118390</th>\n",
       "      <td>OsNippo12g261200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AATGACGGCCACGACGACGACAGGAACGGCGCCTGGATCCGCCGTC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118391</th>\n",
       "      <td>OsNippo12g261600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GCTAGCTGTTACAAGGTTTGTTGGGTAGCCTAGCTACACAAGAAAG...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118392</th>\n",
       "      <td>OsNippo12g261900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GATTTGAAATTTGTTCAGCTTCCGCCCTAGCTTCAGACTCTCTCTC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118393 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Unnamed: 0                                         definition  \\\n",
       "0             GO:0000001  The distribution of mitochondria, including th...   \n",
       "1             GO:0000002  The maintenance of the structure and integrity...   \n",
       "2             GO:0000003  The production of new individuals that contain...   \n",
       "3             GO:0000006  Enables the transfer of zinc ions (Zn2+) from ...   \n",
       "4             GO:0000007  Enables the transfer of a solute or solutes fr...   \n",
       "...                  ...                                                ...   \n",
       "118388  OsNippo12g261100                                                NaN   \n",
       "118389  OsNippo12g261150                                                NaN   \n",
       "118390  OsNippo12g261200                                                NaN   \n",
       "118391  OsNippo12g261600                                                NaN   \n",
       "118392  OsNippo12g261900                                                NaN   \n",
       "\n",
       "                         is_a  \\\n",
       "0       GO:0048311|GO:0048308   \n",
       "1                  GO:0007005   \n",
       "2                  GO:0008150   \n",
       "3                  GO:0005385   \n",
       "4                  GO:0005385   \n",
       "...                       ...   \n",
       "118388                    NaN   \n",
       "118389                    NaN   \n",
       "118390                    NaN   \n",
       "118391                    NaN   \n",
       "118392                    NaN   \n",
       "\n",
       "                                                     name           namespace  \\\n",
       "0                               mitochondrion inheritance  biological_process   \n",
       "1                        mitochondrial genome maintenance  biological_process   \n",
       "2                                            reproduction  biological_process   \n",
       "3       high-affinity zinc transmembrane transporter a...  molecular_function   \n",
       "4       low-affinity zinc ion transmembrane transporte...  molecular_function   \n",
       "...                                                   ...                 ...   \n",
       "118388                                                NaN                 NaN   \n",
       "118389                                                NaN                 NaN   \n",
       "118390                                                NaN                 NaN   \n",
       "118391                                                NaN                 NaN   \n",
       "118392                                                NaN                 NaN   \n",
       "\n",
       "        Annotation score Gene Ontology  \\\n",
       "0                    NaN           NaN   \n",
       "1                    NaN           NaN   \n",
       "2                    NaN           NaN   \n",
       "3                    NaN           NaN   \n",
       "4                    NaN           NaN   \n",
       "...                  ...           ...   \n",
       "118388               NaN           NaN   \n",
       "118389               NaN           NaN   \n",
       "118390               NaN           NaN   \n",
       "118391               NaN           NaN   \n",
       "118392               NaN           NaN   \n",
       "\n",
       "                                         Genomic Sequence  \\\n",
       "0                                                     NaN   \n",
       "1                                                     NaN   \n",
       "2                                                     NaN   \n",
       "3                                                     NaN   \n",
       "4                                                     NaN   \n",
       "...                                                   ...   \n",
       "118388  GCTAGCCGGCGCCGCCCCGACCGTTGCCGTCGCTCGCCGTGTGCTC...   \n",
       "118389  ACTAGCTTATCAGGGGAGCCTTGATGCCGAGAGACATGTGGATTCG...   \n",
       "118390  AATGACGGCCACGACGACGACAGGAACGGCGCCTGGATCCGCCGTC...   \n",
       "118391  GCTAGCTGTTACAAGGTTTGTTGGGTAGCCTAGCTACACAAGAAAG...   \n",
       "118392  GATTTGAAATTTGTTCAGCTTCCGCCCTAGCTTCAGACTCTCTCTC...   \n",
       "\n",
       "       InterPro:description PANTHER  ... Gene Name Synonyms Prosite_patterns  \\\n",
       "0                       NaN     NaN  ...                NaN              NaN   \n",
       "1                       NaN     NaN  ...                NaN              NaN   \n",
       "2                       NaN     NaN  ...                NaN              NaN   \n",
       "3                       NaN     NaN  ...                NaN              NaN   \n",
       "4                       NaN     NaN  ...                NaN              NaN   \n",
       "...                     ...     ...  ...                ...              ...   \n",
       "118388                  NaN     NaN  ...                NaN              NaN   \n",
       "118389                  NaN     NaN  ...                NaN              NaN   \n",
       "118390                  NaN     NaN  ...                NaN              NaN   \n",
       "118391                  NaN     NaN  ...                NaN              NaN   \n",
       "118392                  NaN     NaN  ...                NaN              NaN   \n",
       "\n",
       "       Trait Class Trait Ontology ncoils Keyword  Family  PRINTS  \\\n",
       "0              NaN            NaN    NaN     NaN     NaN     NaN   \n",
       "1              NaN            NaN    NaN     NaN     NaN     NaN   \n",
       "2              NaN            NaN    NaN     NaN     NaN     NaN   \n",
       "3              NaN            NaN    NaN     NaN     NaN     NaN   \n",
       "4              NaN            NaN    NaN     NaN     NaN     NaN   \n",
       "...            ...            ...    ...     ...     ...     ...   \n",
       "118388         NaN            NaN    NaN     NaN     NaN     NaN   \n",
       "118389         NaN            NaN    NaN     NaN     NaN     NaN   \n",
       "118390         NaN            NaN    NaN     NaN     NaN     NaN   \n",
       "118391         NaN            NaN    NaN     NaN     NaN     NaN   \n",
       "118392         NaN            NaN    NaN     NaN     NaN     NaN   \n",
       "\n",
       "       Plant Ontology  Allele  \n",
       "0                 NaN     NaN  \n",
       "1                 NaN     NaN  \n",
       "2                 NaN     NaN  \n",
       "3                 NaN     NaN  \n",
       "4                 NaN     NaN  \n",
       "...               ...     ...  \n",
       "118388            NaN     NaN  \n",
       "118389            NaN     NaN  \n",
       "118390            NaN     NaN  \n",
       "118391            NaN     NaN  \n",
       "118392            NaN     NaN  \n",
       "\n",
       "[118393 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(iric_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebutz/ESL2024/code/utils/train_utils.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_links['source_node'] = df_links.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  genes={ x=[72335, 29] },\n",
      "  go={ x=[42979, 3] },\n",
      "  po={ x=[1662, 2] },\n",
      "  traito={ x=[1636, 1] },\n",
      "  prosite_profiles={ x=[627, 1] },\n",
      "  prosite_patterns={ x=[652, 1] },\n",
      "  superfamily={ x=[957, 1] },\n",
      "  panther={ x=[5971, 1] },\n",
      "  prints={ x=[420, 1] },\n",
      "  (genes, interacts_with, genes)={ edge_index=[2, 1120849] },\n",
      "  (genes, gene_ontology, go)={ edge_index=[2, 169248] },\n",
      "  (genes, trait_ontology, traito)={ edge_index=[2, 15080] },\n",
      "  (genes, plant_ontology, po)={ edge_index=[2, 6125] },\n",
      "  (genes, profile, prosite_profiles)={ edge_index=[2, 12239] },\n",
      "  (genes, pattern, prosite_patterns)={ edge_index=[2, 6677] },\n",
      "  (genes, family, superfamily)={ edge_index=[2, 20742] },\n",
      "  (genes, panther_id, panther)={ edge_index=[2, 25319] },\n",
      "  (genes, prints_id, prints)={ edge_index=[2, 4365] },\n",
      "  (go, is_a, go)={ edge_index=[2, 136436] },\n",
      "  (po, is_a, po)={ edge_index=[2, 3548] },\n",
      "  (traito, is_a, traito)={ edge_index=[2, 3770] },\n",
      "  (go, rev_gene_ontology, genes)={ edge_index=[2, 169248] },\n",
      "  (traito, rev_trait_ontology, genes)={ edge_index=[2, 15080] },\n",
      "  (po, rev_plant_ontology, genes)={ edge_index=[2, 6125] },\n",
      "  (prosite_profiles, rev_profile, genes)={ edge_index=[2, 12239] },\n",
      "  (prosite_patterns, rev_pattern, genes)={ edge_index=[2, 6677] },\n",
      "  (superfamily, rev_family, genes)={ edge_index=[2, 20742] },\n",
      "  (panther, rev_panther_id, genes)={ edge_index=[2, 25319] },\n",
      "  (prints, rev_prints_id, genes)={ edge_index=[2, 4365] }\n",
      ")\n",
      "Function 'split_data' executed in 0.0169s\n",
      "Function 'build_dataloaders' executed in 0.1541s\n"
     ]
    }
   ],
   "source": [
    "data = load_iric_data('/home/ebutz/ESL2024/data/full_iric/iric.csv', featureless=False)\n",
    "data  = T.ToUndirected(merge=True)(data) # Convert the graph to an undirected graph. Creates reverse edges for each edge.\n",
    "data = T.RemoveDuplicatedEdges()(data) # Remove duplicated edges\n",
    "print(data)\n",
    "assert data.validate()\n",
    "\n",
    "train_data, val_data, test_data = split_data(data, config)\n",
    "train_loader, val_loader, test_loader = build_dataloaders(train_data, val_data, test_data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  genes={\n",
      "    x=[25072, 29],\n",
      "    n_id=[25072],\n",
      "    num_sampled_nodes=[6],\n",
      "    src_index=[1024],\n",
      "  },\n",
      "  go={\n",
      "    x=[42976, 3],\n",
      "    n_id=[42976],\n",
      "    num_sampled_nodes=[6],\n",
      "    dst_pos_index=[1024],\n",
      "    dst_neg_index=[1024, 224],\n",
      "  },\n",
      "  po={\n",
      "    x=[1474, 2],\n",
      "    n_id=[1474],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  traito={\n",
      "    x=[1580, 1],\n",
      "    n_id=[1580],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  prosite_profiles={\n",
      "    x=[624, 1],\n",
      "    n_id=[624],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  prosite_patterns={\n",
      "    x=[652, 1],\n",
      "    n_id=[652],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  superfamily={\n",
      "    x=[952, 1],\n",
      "    n_id=[952],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  panther={\n",
      "    x=[5512, 1],\n",
      "    n_id=[5512],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  prints={\n",
      "    x=[420, 1],\n",
      "    n_id=[420],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  (genes, interacts_with, genes)={\n",
      "    edge_index=[2, 486698],\n",
      "    e_id=[486698],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, gene_ontology, go)={\n",
      "    edge_index=[2, 32472],\n",
      "    edge_label=[81240],\n",
      "    e_id=[32472],\n",
      "    num_sampled_edges=[5],\n",
      "    input_id=[1024],\n",
      "  },\n",
      "  (genes, trait_ontology, traito)={\n",
      "    edge_index=[2, 7960],\n",
      "    e_id=[7960],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, plant_ontology, po)={\n",
      "    edge_index=[2, 3053],\n",
      "    e_id=[3053],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, profile, prosite_profiles)={\n",
      "    edge_index=[2, 7568],\n",
      "    e_id=[7568],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, pattern, prosite_patterns)={\n",
      "    edge_index=[2, 4205],\n",
      "    e_id=[4205],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, family, superfamily)={\n",
      "    edge_index=[2, 10859],\n",
      "    e_id=[10859],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, panther_id, panther)={\n",
      "    edge_index=[2, 22679],\n",
      "    e_id=[22679],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, prints_id, prints)={\n",
      "    edge_index=[2, 3164],\n",
      "    e_id=[3164],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (go, is_a, go)={\n",
      "    edge_index=[2, 133081],\n",
      "    e_id=[133081],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (po, is_a, po)={\n",
      "    edge_index=[2, 2949],\n",
      "    e_id=[2949],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (traito, is_a, traito)={\n",
      "    edge_index=[2, 3545],\n",
      "    e_id=[3545],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (go, rev_gene_ontology, genes)={\n",
      "    edge_index=[2, 53616],\n",
      "    e_id=[53616],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (traito, rev_trait_ontology, genes)={\n",
      "    edge_index=[2, 15023],\n",
      "    e_id=[15023],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (po, rev_plant_ontology, genes)={\n",
      "    edge_index=[2, 6072],\n",
      "    e_id=[6072],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (prosite_profiles, rev_profile, genes)={\n",
      "    edge_index=[2, 12131],\n",
      "    e_id=[12131],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (prosite_patterns, rev_pattern, genes)={\n",
      "    edge_index=[2, 6651],\n",
      "    e_id=[6651],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (superfamily, rev_family, genes)={\n",
      "    edge_index=[2, 20391],\n",
      "    e_id=[20391],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (panther, rev_panther_id, genes)={\n",
      "    edge_index=[2, 23973],\n",
      "    e_id=[23973],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (prints, rev_prints_id, genes)={\n",
      "    edge_index=[2, 4300],\n",
      "    e_id=[4300],\n",
      "    num_sampled_edges=[5],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batchy = next(iter(train_loader))\n",
    "print(batchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model to train :\n",
    "# hidden_channels = 176\n",
    "# batch_size      = 4096\n",
    "# epochs          = 200\n",
    "# eval_period     = 2\n",
    "# lin_factor      = 1\n",
    "\n",
    "# use_wandb  = True\n",
    "\n",
    "# params_save_name = f\"PARAMS_ComplEx_6_times_{hidden_channels}_HC_{epochs}_epochs_{batch_size}_BS_on_full_iric\"\n",
    "# model_parameters_path = \"/home/ebutz/ESL2024/data/mapping_datasets_and_model_for_genes_to_phenotypes_iric/\"+params_save_name\n",
    "\n",
    "# # Ontology\n",
    "# ontology_path = \"/home/ebutz/ESL2024/data/go-basic.json.gz\"\n",
    "\n",
    "# # ------------- Cuda ------------- #\n",
    "\n",
    "# print(\"\\nCuda check...\")\n",
    "\n",
    "# device = 'cpu'\n",
    "\n",
    "# # ------------- Loading datas ------------- #\n",
    "\n",
    "# iric = load_iric_data('data/iric.csv', featureless=False)\n",
    "# display(iric)\n",
    "\n",
    "# print(\"\\nLoading iric...\")\n",
    "# mapped_iric = pd.read_pickle(mapped_iric_path)\n",
    "# print(mapped_iric.head())\n",
    "# print('mapped_alt_tails type :', type(mapped_iric.iloc[0]['mapped_alt_tails']))\n",
    "\n",
    "# GO_to_map = mapped_iric.set_index('object')['mapped_object'].to_dict()\n",
    "# map_to_GO = {value: key for key, value in GO_to_map.items()}\n",
    "\n",
    "# if check_dicts:\n",
    "#     looks_ok: bool = True\n",
    "#     for i in tqdm(range(len(list(mapped_iric['object']))), desc = \"Checking GO to MAP dict\"):\n",
    "#         if GO_to_map[mapped_iric['object'][i]]!=mapped_iric['mapped_object'][i] :\n",
    "#             looks_ok = False\n",
    "#     print('GO - Mapping dicts looks ok :', looks_ok)\n",
    "\n",
    "# with open(altails_dict_path, 'rb') as handle:\n",
    "#     mapped_alt_tails = pickle.load(handle)\n",
    "# print(\"Alternative tails dict (first key-value pair):\", list(mapped_alt_tails.items())[0])\n",
    "\n",
    "# # ------------- Loading ontology ------------- #\n",
    "\n",
    "# print(\"\\nLoading ontology...\")\n",
    "# nxo = from_file(ontology_path)\n",
    "# nxo.freeze()\n",
    "# pwc.nxo = nxo\n",
    "\n",
    "# # ------------- Making global variables accessibles to pwc ------------- #\n",
    "\n",
    "# pwc.map_to_GO        = map_to_GO\n",
    "# pwc.mapped_alt_tails = mapped_alt_tails\n",
    "# pwc.device           = device\n",
    "\n",
    "# # ------------- Making datasets ------------- #\n",
    "\n",
    "\n",
    "# print(\"\\nDataset looks valid :\",hetero_iric.validate(raise_on_error=True))\n",
    "\n",
    "# print('All done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_layers = get_gnn_layers(config)\n",
    "norm_layers = get_norm_layers(config, len(data.node_types))\n",
    "\n",
    "model = Model(config, data, norm_layers, gnn_layers).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-sparse\n",
      "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages (from torch-sparse) (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages (from scipy->torch-sparse) (1.26.4)\n",
      "Building wheels for collected packages: torch-sparse\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[113 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/__init__.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/add.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/bandwidth.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/cat.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/convert.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/diag.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/eye.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/index_select.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/masked_select.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/matmul.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/metis.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/mul.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/narrow.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/permute.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/reduce.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/rw.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/saint.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/sample.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/select.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spadd.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spmm.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/storage.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/tensor.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/testing.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/transpose.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/typing.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/utils.py -> build/lib.linux-x86_64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_sparse.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_sparse.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_sparse.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_sparse.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/css'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/html'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/tests'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/examples'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/benchmark'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'benchmark'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m /home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/utils/cpp_extension.py:388: UserWarning:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m                                !! WARNING !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "  \u001b[31m   \u001b[0m Your compiler (g++ 4.9.2) may be ABI-incompatible with PyTorch!\n",
      "  \u001b[31m   \u001b[0m Please use a compiler that is ABI-compatible with GCC 5.0 and above.\n",
      "  \u001b[31m   \u001b[0m See https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m See https://gist.github.com/goldsborough/d466f43e8ffc948ff92de7486c5216d6\n",
      "  \u001b[31m   \u001b[0m for instructions on how to install GCC 5 or higher.\n",
      "  \u001b[31m   \u001b[0m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m                               !! WARNING !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   warnings.warn(ABI_INCOMPATIBILITY_WARNING.format(compiler))\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-f_uyf6k9/torch-sparse_202511b3784143efad55a3c5205f91f6/setup.py\", line 147, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/__init__.py\", line 103, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/dist.py\", line 989, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/wheel/bdist_wheel.py\", line 299, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command('build')\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/dist.py\", line 989, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/_distutils/command/build.py\", line 131, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/dist.py\", line 989, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/command/build_ext.py\", line 88, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/setuptools/_distutils/command/build_ext.py\", line 345, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 523, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     _check_cuda_version(compiler_name, compiler_version)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 414, in _check_cuda_version\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError(CUDA_MISMATCH_MESSAGE.format(cuda_str_version, torch.version.cuda))\n",
      "  \u001b[31m   \u001b[0m RuntimeError:\n",
      "  \u001b[31m   \u001b[0m The detected CUDA version (7.5) mismatches the version that was used to compile\n",
      "  \u001b[31m   \u001b[0m PyTorch (12.1). Please make sure to use the same CUDA versions.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torch-sparse\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torch-sparse\n",
      "Failed to build torch-sparse\n",
      "\u001b[31mERROR: Could not build wheels for torch-sparse, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install torch-sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This file may be used to create an environment using:\n",
      "# $ conda create --name <env> --file <this file>\n",
      "# platform: linux-64\n",
      "@EXPLICIT\n",
      "https://conda.anaconda.org/conda-forge/linux-64/_libgcc_mutex-0.1-conda_forge.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/noarch/_sysroot_linux-64_curr_repodata_hack-3-haa98f57_10.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/blas-1.0-openblas.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/ca-certificates-2024.3.11-h06a4308_0.conda\n",
      "https://conda.anaconda.org/anaconda/noarch/font-ttf-dejavu-sans-mono-2.37-hd3eb1b0_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/noarch/font-ttf-inconsolata-2.001-hcb22688_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/noarch/font-ttf-source-code-pro-2.030-hd3eb1b0_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/noarch/font-ttf-ubuntu-0.83-h8b1ccd4_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/ld_impl_linux-64-2.40-h41732ed_0.conda\n",
      "https://conda.anaconda.org/conda-forge/noarch/libgcc-devel_linux-64-13.2.0-h95c4c6d_106.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libgfortran5-11.2.0-h1234567_1.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libstdcxx-ng-13.2.0-h7e041cc_5.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/poppler-data-0.4.11-h06a4308_1.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/tzdata-2024a-h0c530f3_0.conda\n",
      "https://conda.anaconda.org/anaconda/noarch/fonts-anaconda-1-h8fa9717_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/noarch/kernel-headers_linux-64-3.10.0-h57e8cba_10.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libgfortran-ng-11.2.0-h00389a5_1.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libgomp-13.2.0-h807b86a_5.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/_openmp_mutex-4.5-2_gnu.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/noarch/fonts-conda-ecosystem-1-hd3eb1b0_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/noarch/sysroot_linux-64-2.17-h57e8cba_10.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/binutils_impl_linux-64-2.40-hf600244_0.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libgcc-ng-13.2.0-h807b86a_5.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/bzip2-1.0.8-hd590300_5.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/c-ares-1.19.1-h5eee18b_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/fribidi-1.0.10-h7b6447c_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/giflib-5.2.1-h5eee18b_3.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/graphite2-1.3.14-h295c915_1.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/icu-58.2-he6710b0_3.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/jpeg-9e-h5eee18b_1.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/lerc-3.0-h295c915_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/libdeflate-1.17-h5eee18b_1.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/libev-4.33-h7f8727e_1.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libexpat-2.6.2-h59595ed_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libffi-3.4.4-h6a678d5_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/libiconv-1.16-h7f8727e_2.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libnsl-2.0.1-hd590300_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libopenblas-0.3.21-h043d6bf_0.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libsanitizer-13.2.0-h95c4c6d_6.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libsodium-1.0.18-h36c2ea0_1.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/libtool-2.4.6-h6a678d5_1009.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libuuid-1.41.5-h5eee18b_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/libwebp-base-1.2.4-h5eee18b_1.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/libxcb-1.15-h7f8727e_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libxcrypt-4.4.36-hd590300_1.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libzlib-1.2.13-hd590300_5.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/lz4-c-1.9.4-h6a678d5_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/ncurses-6.4.20240210-h59595ed_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/ninja-base-1.10.2-hd09550d_5.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/nspr-4.35-h6a678d5_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/openssl-3.0.13-h7f8727e_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/pcre-8.45-h295c915_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/pixman-0.40.0-h7f8727e_1.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/xz-5.4.6-h5eee18b_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/yaml-0.2.5-h7b6447c_0.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/expat-2.6.2-h59595ed_0.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/gcc_impl_linux-64-13.2.0-h1d3d475_6.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/libedit-3.1.20221030-h5eee18b_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/linux-64/libsqlite-3.45.2-h2797004_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libssh2-1.10.0-hdbd6064_2.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/readline-8.2-h8228510_1.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/tk-8.6.13-noxft_h4845f30_101.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/zeromq-4.3.5-h59595ed_1.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/zlib-1.2.13-hd590300_5.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/gcc-13.2.0-hc7bed06_6.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/krb5-1.20.1-h143b758_1.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libnghttp2-1.57.0-h2d74bed_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/libpng-1.6.39-h5eee18b_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libprotobuf-3.20.3-he621ea3_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/libxml2-2.9.14-h74e7548_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/pcre2-10.42-hebb0a14_0.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/sqlite-3.45.2-h2c6b66d_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/zstd-1.5.5-hc292b87_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/freetype-2.12.1-h4a9f257_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/libboost-1.73.0-h28710b8_12.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libcurl-8.5.0-h251f7ec_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/libglib-2.78.4-hdc74915_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/libtiff-4.5.1-h6a678d5_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/nss-3.89.1-h6a678d5_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/python-3.10.14-h955ad1f_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/appdirs-1.4.4-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/backcall-0.2.0-pyhd3eb1b0_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/boost-cpp-1.73.0-h7f8727e_12.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/brotli-python-1.0.9-py310h6a678d5_7.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/certifi-2024.2.2-py310h06a4308_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/charset-normalizer-2.0.4-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/click-8.1.7-py310h06a4308_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/colorama-0.4.4-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/debugpy-1.6.7-py310h6a678d5_0.conda\n",
      "https://conda.anaconda.org/conda-forge/noarch/decorator-5.1.1-pyhd8ed1ab_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/entrypoints-0.4-py310h06a4308_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/exceptiongroup-1.2.0-py310h06a4308_0.conda\n",
      "https://conda.anaconda.org/conda-forge/noarch/executing-2.0.1-pyhd8ed1ab_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/fontconfig-2.14.1-hef1e5e3_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/glib-tools-2.78.4-h6a678d5_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/gobject-introspection-1.78.1-py310hd56c82f_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/idna-3.4-py310h06a4308_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/ipython_genutils-0.2.0-pyhd3eb1b0_1.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/lcms2-2.12-h3be6417_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/libwebp-1.2.4-h11a3e52_1.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/nest-asyncio-1.6.0-pyhd8ed1ab_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/ninja-1.10.2-h06a4308_5.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/numpy-base-1.26.4-py310h8a23956_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/openjpeg-2.4.0-h3ad879b_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/noarch/parso-0.8.3-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/pathtools-0.1.2-pyhd3eb1b0_1.conda\n",
      "https://conda.anaconda.org/conda-forge/noarch/pickleshare-0.7.5-py_1003.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/platformdirs-3.10.0-py310h06a4308_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/protobuf-3.20.3-py310h6a678d5_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/psutil-5.9.0-py310h5eee18b_0.conda\n",
      "https://conda.anaconda.org/conda-forge/noarch/ptyprocess-0.7.0-pyhd3deb0d_0.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/pure_eval-0.2.2-pyhd8ed1ab_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/noarch/pygments-2.11.2-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/pyparsing-3.0.4-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/pysocks-1.7.1-py310h06a4308_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/python-tzdata-2023.3-pyhd3eb1b0_0.conda\n",
      "https://conda.anaconda.org/conda-forge/linux-64/python_abi-3.10-2_cp310.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/noarch/pytz-2021.3-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/pyyaml-6.0.1-py310h5eee18b_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/pyzmq-25.1.2-py310h6a678d5_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/setproctitle-1.2.2-py310h7f8727e_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/setuptools-68.2.2-py310h06a4308_0.conda\n",
      "https://conda.anaconda.org/conda-forge/noarch/six-1.16.0-pyh6c4a22f_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/noarch/smmap-4.0.0-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/tornado-6.3.3-py310h5eee18b_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/traitlets-5.7.1-py310h06a4308_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/wcwidth-0.2.5-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/wheel-0.37.1-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/zipp-3.6.0-pyhd3eb1b0_0.conda\n",
      "https://conda.anaconda.org/conda-forge/noarch/asttokens-2.4.1-pyhd8ed1ab_0.conda\n",
      "https://conda.anaconda.org/conda-forge/noarch/comm-0.1.1-pyhd8ed1ab_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/docker-pycreds-0.4.0-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/gitdb-4.0.7-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/glib-2.78.4-h6a678d5_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/importlib-metadata-7.0.1-py310h06a4308_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/jedi-0.18.1-py310h06a4308_1.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/jupyter_core-5.5.0-py310h06a4308_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/libgd-2.3.3-h6a678d5_3.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/matplotlib-inline-0.1.6-pyhd8ed1ab_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/numpy-1.26.4-py310heeff2f4_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/packaging-21.3-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/pexpect-4.8.0-pyhd3eb1b0_3.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/pip-23.3.1-py310h06a4308_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/prompt-toolkit-3.0.43-py310h06a4308_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/python-dateutil-2.8.2-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/tqdm-4.63.0-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/urllib3-2.1.0-py310h06a4308_1.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/atk-1.0-2.36.0-ha1a6a79_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/bottleneck-1.3.7-py310ha9d4c09_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/cairo-1.16.0-hb05425b_5.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/colorspacious-1.1.2-pyh24bf2e0_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/gdk-pixbuf-2.42.10-h5eee18b_0.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/gitpython-3.1.37-py310h06a4308_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/gts-0.7.6-hb67d8dd_3.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/noarch/importlib_metadata-7.0.1-hd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/jupyter_client-7.1.2-pyhd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/numexpr-2.8.7-py310h286c3b5_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/noarch/prompt_toolkit-3.0.43-hd3eb1b0_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/requests-2.31.0-py310h06a4308_1.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/sentry-sdk-1.9.0-py310h06a4308_0.conda\n",
      "https://conda.anaconda.org/conda-forge/noarch/stack_data-0.6.2-pyhd8ed1ab_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/harfbuzz-4.3.0-hf52aaf7_1.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/ipython-8.20.0-py310h06a4308_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/pandas-2.2.1-py310h6a678d5_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/poppler-22.12.0-h9614445_3.tar.bz2\n",
      "https://conda.anaconda.org/conda-forge/noarch/wandb-0.16.5-pyhd8ed1ab_0.conda\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/ipykernel-6.28.0-py310h06a4308_0.conda\n",
      "https://conda.anaconda.org/anaconda/linux-64/pango-1.50.7-h05da053_0.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/gtk2-2.24.33-h73c1081_2.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/librsvg-2.54.4-h36cc946_2.tar.bz2\n",
      "https://conda.anaconda.org/anaconda/linux-64/graphviz-2.50.0-h1b29801_1.tar.bz2\n",
      "https://repo.anaconda.com/pkgs/main/linux-64/pygraphviz-1.9-py310h5eee18b_1.conda\n"
     ]
    }
   ],
   "source": [
    "# conda list\n",
    "! conda list --explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install https://repo.anaconda.com/pkgs/main/linux-64/urllib3-2.1.0-py310h06a4308_1.conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cuda'\n",
      "Model(\n",
      "  (encoder): GraphModule(\n",
      "    (convs): ModuleList(\n",
      "      (0-2): 3 x ModuleDict(\n",
      "        (genes__interacts_with__genes): ResGatedGraphConv((-1, -1), 115)\n",
      "        (genes__gene_ontology__go): ResGatedGraphConv((-1, -1), 115)\n",
      "        (genes__trait_ontology__traito): ResGatedGraphConv((-1, -1), 115)\n",
      "        (genes__plant_ontology__po): ResGatedGraphConv((-1, -1), 115)\n",
      "        (genes__profile__prosite_profiles): ResGatedGraphConv((-1, -1), 115)\n",
      "        (genes__pattern__prosite_patterns): ResGatedGraphConv((-1, -1), 115)\n",
      "        (genes__family__superfamily): ResGatedGraphConv((-1, -1), 115)\n",
      "        (genes__panther_id__panther): ResGatedGraphConv((-1, -1), 115)\n",
      "        (genes__prints_id__prints): ResGatedGraphConv((-1, -1), 115)\n",
      "        (go__is_a__go): ResGatedGraphConv((-1, -1), 115)\n",
      "        (po__is_a__po): ResGatedGraphConv((-1, -1), 115)\n",
      "        (traito__is_a__traito): ResGatedGraphConv((-1, -1), 115)\n",
      "        (go__rev_gene_ontology__genes): ResGatedGraphConv((-1, -1), 115)\n",
      "        (traito__rev_trait_ontology__genes): ResGatedGraphConv((-1, -1), 115)\n",
      "        (po__rev_plant_ontology__genes): ResGatedGraphConv((-1, -1), 115)\n",
      "        (prosite_profiles__rev_profile__genes): ResGatedGraphConv((-1, -1), 115)\n",
      "        (prosite_patterns__rev_pattern__genes): ResGatedGraphConv((-1, -1), 115)\n",
      "        (superfamily__rev_family__genes): ResGatedGraphConv((-1, -1), 115)\n",
      "        (panther__rev_panther_id__genes): ResGatedGraphConv((-1, -1), 115)\n",
      "        (prints__rev_prints_id__genes): ResGatedGraphConv((-1, -1), 115)\n",
      "      )\n",
      "    )\n",
      "    (norm): ModuleDict(\n",
      "      (genes): DiffGroupNorm(115, groups=9)\n",
      "      (go): DiffGroupNorm(115, groups=9)\n",
      "      (po): DiffGroupNorm(115, groups=9)\n",
      "      (traito): DiffGroupNorm(115, groups=9)\n",
      "      (prosite_profiles): DiffGroupNorm(115, groups=9)\n",
      "      (prosite_patterns): DiffGroupNorm(115, groups=9)\n",
      "      (superfamily): DiffGroupNorm(115, groups=9)\n",
      "      (panther): DiffGroupNorm(115, groups=9)\n",
      "      (prints): DiffGroupNorm(115, groups=9)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(\n",
      "    (lin1): Linear(in_features=230, out_features=115, bias=True)\n",
      "    (lin2): Linear(in_features=115, out_features=1, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (norm): DiffGroupNorm(115, groups=9)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/80 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Caught ImportError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch_geometric/loader/link_loader.py\", line 211, in collate_fn\n    out = self.link_sampler.sample_from_edges(\n  File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch_geometric/sampler/neighbor_sampler.py\", line 334, in sample_from_edges\n    out = edge_sample(inputs, self._sample, self.num_nodes, self.disjoint,\n  File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch_geometric/sampler/neighbor_sampler.py\", line 666, in edge_sample\n    out = sample_fn(seed_dict, seed_time_dict)\n  File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch_geometric/sampler/neighbor_sampler.py\", line 431, in _sample\n    raise ImportError(f\"'{self.__class__.__name__}' requires \"\nImportError: 'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 184\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;66;03m# early_stopper(score)\u001b[39;00m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;66;03m# if early_stopper.early_stop:\u001b[39;00m\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m#     print(\"Early stopping triggered at epoch\", epoch)\u001b[39;00m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining done.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 184\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m evaluate(config, val_loader, model, criterion, compute_all_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, loader_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m, stopper_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    186\u001b[0m evaluate(config, test_loader, model, criterion, compute_all_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, loader_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, stopper_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/ESL2024/code/utils/train_utils.py:25\u001b[0m, in \u001b[0;36mtimer_func.<locals>.wrap_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \n\u001b[1;32m     24\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time() \n\u001b[0;32m---> 25\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     26\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m time() \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m executed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(t2\u001b[38;5;241m-\u001b[39mt1)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "Cell \u001b[0;32mIn[44], line 148\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config, train_loader, val_loader, model, criterion, optimizer, early_stopper)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    146\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m total_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sampled_data \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    150\u001b[0m         sampled_data \u001b[38;5;241m=\u001b[39m sampled_data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    151\u001b[0m         pred \u001b[38;5;241m=\u001b[39m model(sampled_data, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mImportError\u001b[0m: Caught ImportError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch_geometric/loader/link_loader.py\", line 211, in collate_fn\n    out = self.link_sampler.sample_from_edges(\n  File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch_geometric/sampler/neighbor_sampler.py\", line 334, in sample_from_edges\n    out = edge_sample(inputs, self._sample, self.num_nodes, self.disjoint,\n  File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch_geometric/sampler/neighbor_sampler.py\", line 666, in edge_sample\n    out = sample_fn(seed_dict, seed_time_dict)\n  File \"/home/ebutz/miniconda3/envs/pyg/lib/python3.10/site-packages/torch_geometric/sampler/neighbor_sampler.py\", line 431, in _sample\n    raise ImportError(f\"'{self.__class__.__name__}' requires \"\nImportError: 'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------- Loops ----------------- #\n",
    "@timer_func\n",
    "def evaluate(config, loader, model, criterion, compute_all_metrics=False, loader_type='validation', stopper_metric=False):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given data loader.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : object\n",
    "        An object containing the configuration parameters for the model.    \n",
    "    loader : DataLoader\n",
    "        The data loader to evaluate the model on.\n",
    "    model : Model\n",
    "        The model to evaluate.\n",
    "    criterion : callable\n",
    "        The loss function to use for evaluation.\n",
    "    compute_all_metrics : bool, optional\n",
    "        Whether to compute all metrics or partially. Default is False.\n",
    "    loader_type : str, optional\n",
    "        The type of the loader ('validation' or 'test'). Default is 'validation'.\n",
    "    stopper_metric : str or bool, optional\n",
    "        The metric that dictates when to stop training. If False, only the loss is computed. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple of the evaluation metric and the loss, depending on the value of `stopper_metric`.\n",
    "        If compute_all_metrics is True, the function logs all metrics to W&B.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    num_neg_samples = loader.neg_sampling.amount\n",
    "    with torch.no_grad():\n",
    "        if stopper_metric or compute_all_metrics:\n",
    "            ground_truths = torch.tensor([], device='cpu')\n",
    "            preds = torch.tensor([], device='cpu')\n",
    "            indexes = torch.tensor([], device='cpu')\n",
    "            total_loss, total_examples = 0, 0\n",
    "            index_end = loader.batch_size\n",
    "\n",
    "        for sampled_data in loader:\n",
    "            sampled_data = sampled_data.to(device)\n",
    "\n",
    "            batch_size = len(sampled_data[config.labels['tail']].dst_pos_index)\n",
    "            pred = model(sampled_data, config)\n",
    "            pos_samples = torch.ones(batch_size, device=device)\n",
    "            neg_samples = torch.zeros(num_neg_samples*batch_size, device=device)\n",
    "            ground_truth = torch.cat((pos_samples, neg_samples))\n",
    "\n",
    "            if stopper_metric or compute_all_metrics: # Store preds and truths for all batches, and compute indices to calc metrics\n",
    "                index_pos = torch.arange(end=index_end, start=index_end-batch_size) # index for predictions with pos. ground_truth\n",
    "                index_neg = torch.arange(end=index_end, start=index_end-batch_size).repeat_interleave(num_neg_samples)\n",
    "                index = torch.cat((index_pos, index_neg))\n",
    "                indexes = torch.cat((indexes, index.to('cpu')))\n",
    "                preds = torch.cat((preds, pred.to('cpu')))\n",
    "                ground_truths = torch.cat((ground_truths, ground_truth.to('cpu')))\n",
    "                index_end += batch_size\n",
    "\n",
    "            eval_loss = criterion(pred, ground_truth, gamma=config.gamma, alpha=config.alpha)\n",
    "\n",
    "            # if not stopper_metric: # Just logging loss\n",
    "            #     wandb.log({\"running_val_loss\": eval_loss})\n",
    "            #     break\n",
    "            # else:\n",
    "            total_loss += float(eval_loss) * pred.numel() \n",
    "            total_examples += pred.numel()\n",
    "            eval_loss = total_loss / total_examples\n",
    "\n",
    "            # if stopper_metric and not compute_all_metrics:\n",
    "            #     if index_end >= 2048: # Compute approx. intermediate metric on a few datapoints to speed up hyperopt process\n",
    "            #         break \n",
    "\n",
    "        model.train()\n",
    "\n",
    "        if stopper_metric and not compute_all_metrics: # Compute only the metric that dictates stopping\n",
    "            indexes = indexes.long()\n",
    "\n",
    "            # # Log heatmap between prediction and ground truth. Useful for visualization / debugging. overhead 0.2s per epoch for a single sample.\n",
    "            # heatmap = heatmaps(preds, ground_truths, indexes) \n",
    "            # wandb.log({f\"heatmap\": wandb.Image(heatmap)})\n",
    "            # heatmap.close() # Free up memory\n",
    "\n",
    "            match stopper_metric:\n",
    "                case \"val_loss\":\n",
    "                    eval_loss = total_loss / total_examples\n",
    "                    return eval_loss\n",
    "                \n",
    "                case \"mrr\":\n",
    "                    mrr = RetrievalMRR().to(device)\n",
    "                    return mrr(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_10\":\n",
    "                    hit_at_10 = RetrievalHitRate(top_k=10).to(device)\n",
    "                    return hit_at_10(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_5\":\n",
    "                    hit_at_5 = RetrievalHitRate(top_k=5).to(device)\n",
    "                    return hit_at_5(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_3\":\n",
    "                    hit_at_3 = RetrievalHitRate(top_k=3).to(device)\n",
    "                    return hit_at_3(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_1\":\n",
    "                    hit_at_1 = RetrievalHitRate(top_k=1).to(device)\n",
    "                    return hit_at_1(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case _:\n",
    "                    raise ValueError(f\"Unrecognized stopper metric: '{stopper_metric}'\")\n",
    "                \n",
    "        if compute_all_metrics: # Compute all metrics at the end of training\n",
    "            indexes = indexes.long()\n",
    "            mrr = RetrievalMRR().to(device)\n",
    "            hit_at_10 = RetrievalHitRate(top_k=10).to(device)\n",
    "            hit_at_5 = RetrievalHitRate(top_k=5).to(device)\n",
    "            hit_at_3 = RetrievalHitRate(top_k=3).to(device)\n",
    "            hit_at_1 = RetrievalHitRate(top_k=1).to(device)\n",
    "            \n",
    "            mrr = mrr(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_10 = hit_at_10(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_5 = hit_at_5(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_3 = hit_at_3(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_1 = hit_at_1(preds, ground_truths, indexes=indexes)\n",
    "\n",
    "            wandb.log({\n",
    "                f\"{loader_type}MRR\": mrr, f\"{loader_type}hit_at_10\": hit_at_10, f\"{loader_type}hit_at_5\": hit_at_5, f\"{loader_type}hit_at_3\": hit_at_3, f\"{loader_type}hit_at_1\": hit_at_1\n",
    "            })\n",
    "\n",
    "\n",
    "# Set device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: '{device}'\")\n",
    "\n",
    "model = Model(config, data, norm_layers, gnn_layers).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = sigmoid_focal_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "# optimizer = Lion(model.parameters(), lr=config.lr, weight_decay=1e-2)\n",
    "early_stopper = EarlyStopper(frequency=config.stopper_frequency, patience=config.stopper_patience, direction=config.stopper_direction, relative_delta=config.stopper_relative_delta)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "@timer_func\n",
    "def train(config, train_loader, val_loader, model, criterion, optimizer, early_stopper):\n",
    "    for epoch in range(config.epochs):\n",
    "        total_loss = total_examples = 0\n",
    "\n",
    "        for sampled_data in tqdm(train_loader, desc=\"Training\"):\n",
    "\n",
    "            sampled_data = sampled_data.to(device)\n",
    "            pred = model(sampled_data, config)\n",
    "            print(sampled_data)\n",
    "\n",
    "            pos_samples = torch.ones(len(sampled_data[config.labels['tail']].dst_pos_index), device=device)\n",
    "            neg_samples = torch.zeros(len(sampled_data[config.labels['tail']].dst_neg_index.view(-1)), device=device) # As many zeroes as there are negative samples * batch_size\n",
    "            ground_truth = torch.cat((pos_samples, neg_samples))\n",
    "            # Add gaussian noise to pos_samples to simulate noisy labels. Added noise must be negative and not exceed 1.\n",
    "            # ground_truth += torch.normal(mean=0, std=1, size=(len(ground_truth),), device=device)\n",
    "            # apply sigmoid\n",
    "            ground_truth = torch.sigmoid(ground_truth)\n",
    "            # ground_truth = torch.sigmoid(ground_truth)\n",
    "            loss = criterion(pred, ground_truth, gamma=config.gamma, alpha=config.alpha)\n",
    "            wandb.log({\"loss\": loss})\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += float(loss) * pred.numel()\n",
    "            total_examples += pred.numel()\n",
    "        train_loss = total_loss / total_examples\n",
    "        print(f\"Epoch: {epoch:03d}, Avg. Loss: {train_loss:.10f}\")\n",
    "        # scheduler.step()\n",
    "\n",
    "        # Compute metrics and check for early stopping\n",
    "        score, val_loss = evaluate(config, val_loader, model, criterion, stopper_metric=config.stopper_metric)\n",
    "        wandb.log({\"avg_loss\": train_loss, \"val_loss\": val_loss, f\"{config.stopper_metric}\": score})\n",
    "\n",
    "        # early_stopper(score)\n",
    "        # if early_stopper.early_stop:\n",
    "        #     print(\"Early stopping triggered at epoch\", epoch)\n",
    "        #     break\n",
    "\n",
    "    print(\"Training done.\")\n",
    "\n",
    "train(config, train_loader, val_loader, model, criterion, optimizer, early_stopper)\n",
    "evaluate(config, val_loader, model, criterion, compute_all_metrics=True, loader_type='validation', stopper_metric=False)\n",
    "evaluate(config, test_loader, model, criterion, compute_all_metrics=True, loader_type='test', stopper_metric=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
