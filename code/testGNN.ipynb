{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cpu'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1piulxy7) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Baseline</strong> at: <a href='https://wandb.ai/esl2024/First%20try%20GNN/runs/1piulxy7' target=\"_blank\">https://wandb.ai/esl2024/First%20try%20GNN/runs/1piulxy7</a><br/> View project at: <a href='https://wandb.ai/esl2024/First%20try%20GNN' target=\"_blank\">https://wandb.ai/esl2024/First%20try%20GNN</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240425_093332-1piulxy7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1piulxy7). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ebutz/ESL2024/code/wandb/run-20240425_093741-3bqjewgx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esl2024/First%20try%20GNN/runs/3bqjewgx' target=\"_blank\">Baseline</a></strong> to <a href='https://wandb.ai/esl2024/First%20try%20GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esl2024/First%20try%20GNN' target=\"_blank\">https://wandb.ai/esl2024/First%20try%20GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esl2024/First%20try%20GNN/runs/3bqjewgx' target=\"_blank\">https://wandb.ai/esl2024/First%20try%20GNN/runs/3bqjewgx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'wandb.sdk.wandb_config.Config'>\n",
      "False\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebutz/ESL2024/code/utils/train_utils.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_links['source_node'] = df_links.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  genes={ x=[72335, 29] },\n",
      "  go={ x=[42979, 3] },\n",
      "  po={ x=[1662, 2] },\n",
      "  traito={ x=[1636, 1] },\n",
      "  prosite_profiles={ x=[627, 1] },\n",
      "  prosite_patterns={ x=[652, 1] },\n",
      "  superfamily={ x=[957, 1] },\n",
      "  panther={ x=[5971, 1] },\n",
      "  prints={ x=[420, 1] },\n",
      "  (genes, interacts_with, genes)={ edge_index=[2, 1120849] },\n",
      "  (genes, gene_ontology, go)={ edge_index=[2, 169248] },\n",
      "  (genes, trait_ontology, traito)={ edge_index=[2, 15080] },\n",
      "  (genes, plant_ontology, po)={ edge_index=[2, 6125] },\n",
      "  (genes, profile, prosite_profiles)={ edge_index=[2, 12239] },\n",
      "  (genes, pattern, prosite_patterns)={ edge_index=[2, 6677] },\n",
      "  (genes, family, superfamily)={ edge_index=[2, 20742] },\n",
      "  (genes, panther_id, panther)={ edge_index=[2, 25319] },\n",
      "  (genes, prints_id, prints)={ edge_index=[2, 4365] },\n",
      "  (go, is_a, go)={ edge_index=[2, 136436] },\n",
      "  (po, is_a, po)={ edge_index=[2, 3548] },\n",
      "  (traito, is_a, traito)={ edge_index=[2, 3770] },\n",
      "  (go, rev_gene_ontology, genes)={ edge_index=[2, 169248] },\n",
      "  (traito, rev_trait_ontology, genes)={ edge_index=[2, 15080] },\n",
      "  (po, rev_plant_ontology, genes)={ edge_index=[2, 6125] },\n",
      "  (prosite_profiles, rev_profile, genes)={ edge_index=[2, 12239] },\n",
      "  (prosite_patterns, rev_pattern, genes)={ edge_index=[2, 6677] },\n",
      "  (superfamily, rev_family, genes)={ edge_index=[2, 20742] },\n",
      "  (panther, rev_panther_id, genes)={ edge_index=[2, 25319] },\n",
      "  (prints, rev_prints_id, genes)={ edge_index=[2, 4365] }\n",
      ")\n",
      "Function 'split_data' executed in 0.0155s\n",
      "Function 'build_dataloaders' executed in 0.1538s\n",
      "\n",
      "Loading ontology...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|‚ñç         | 3/80 [00:21<09:12,  7.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 364\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[38;5;66;03m# early_stopper(score)\u001b[39;00m\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;66;03m# if early_stopper.early_stop:\u001b[39;00m\n\u001b[1;32m    359\u001b[0m         \u001b[38;5;66;03m#     print(\"Early stopping triggered at epoch\", epoch)\u001b[39;00m\n\u001b[1;32m    360\u001b[0m         \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining done.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 364\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m evaluate(config,  val_loader, model, criterion, compute_all_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, loader_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m, stopper_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    366\u001b[0m evaluate(config, test_loader, model, criterion, compute_all_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, loader_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m      , stopper_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/ESL2024/code/utils/train_utils.py:25\u001b[0m, in \u001b[0;36mtimer_func.<locals>.wrap_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \n\u001b[1;32m     24\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time() \n\u001b[0;32m---> 25\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     26\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m time() \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m executed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(t2\u001b[38;5;241m-\u001b[39mt1)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "Cell \u001b[0;32mIn[6], line 328\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config, train_loader, val_loader, model, criterion, optimizer, early_stopper)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sampled_data \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    327\u001b[0m     sampled_data \u001b[38;5;241m=\u001b[39m sampled_data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 328\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;66;03m# print(sampled_data)\u001b[39;00m\n\u001b[1;32m    331\u001b[0m     true_tails \u001b[38;5;241m=\u001b[39m sampled_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdst_pos_index\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ESL2024/code/utils/model_utils.py:262\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, sampled_data, config)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sampled_data, config):\n\u001b[1;32m    261\u001b[0m     z_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(sampled_data\u001b[38;5;241m.\u001b[39mx_dict, sampled_data\u001b[38;5;241m.\u001b[39medge_index_dict)\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampled_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ESL2024/code/utils/model_utils.py:155\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, z_dict, sampled_data, config)\u001b[0m\n\u001b[1;32m    153\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm:\n\u001b[0;32m--> 155\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m    157\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch_geometric/nn/norm/diff_group_norm.py:80\u001b[0m, in \u001b[0;36mDiffGroupNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [N, G]\u001b[39;00m\n\u001b[1;32m     79\u001b[0m out \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# [N, G, F]\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m(out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, G \u001b[38;5;241m*\u001b[39m F))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, G, F)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# [N, F]\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlamda \u001b[38;5;241m*\u001b[39m out\n",
      "File \u001b[0;32m~/miniconda3/envs/pyg2/lib/python3.11/site-packages/torch/nn/modules/module.py:1682\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1682\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1683\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1684\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/ebutz/ESL2024/code/utils' )\n",
    "import optuna\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.sampler import NegativeSampling\n",
    "import torch_geometric.transforms as T\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import ComplEx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from nxontology.imports import from_file\n",
    "import wandb\n",
    "from play_with_complex import *\n",
    "from data_utils import *\n",
    "from train_utils import *\n",
    "from model_utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from torchmetrics.retrieval import RetrievalMRR, RetrievalHitRate\n",
    "import play_with_complex as pwc\n",
    "#¬†Wandb\n",
    "xp_name = 'First try GNN'\n",
    "run_name = 'Baseline'\n",
    "\n",
    "#¬†Iric\n",
    "iric_path = '/home/ebutz/ESL2024/data/full_iric/iric.csv'\n",
    "mapped_iric_path  = '/home/ebutz/ESL2024/data/full_iric/altailed_mapped_iric.pickle'\n",
    "altails_dict_path = '/home/ebutz/ESL2024/data/full_iric/altail_iric_DICT.pickle'\n",
    "check_dicts = True\n",
    "\n",
    "ontology_path = '/home/ebutz/ESL2024/data/go-basic.json.gz'\n",
    "\n",
    "# Set device\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print(f\"Device: '{device}'\")\n",
    "\n",
    "\n",
    "run = wandb.init(project=xp_name, name = run_name)\n",
    "config = wandb.config\n",
    "config.val_ratio=0.1\n",
    "config.homogeneous=False\n",
    "config.scorelist_size=1000\n",
    "config.split_ratio=0.8\n",
    "config.val_ratio=0.1\n",
    "config.test_ratio=0.1\n",
    "config.num_neighbors=[70,55,13,89,85]\n",
    "config.batch_size=1024\n",
    "config.train_neg_sampling_ratio=224\n",
    "config.epochs=18\n",
    "config.disjoint_train_ratio=0.6\n",
    "config.lr=0.0015308253347932983\n",
    "config.stopper_metric= 'mrr'\n",
    "config.stopper_direction=\"maximize\"\n",
    "config.stopper_patience=5\n",
    "config.stopper_frequency=1\n",
    "config.stopper_relative_delta=0.05\n",
    "config.gamma=1.3\n",
    "config.alpha=0.42680473078813763\n",
    "config.gnn_layer='ResGatedGraphConv'\n",
    "config.dropout=0.1\n",
    "config.norm='DiffGroupNorm'\n",
    "config.aggregation = 'min'\n",
    "config.hidden_channels=115\n",
    "config.num_layers=3\n",
    "config.attention_heads=4\n",
    "config.homogeneous = False\n",
    "config.labels = {'head' : 'genes', 'relation' : 'gene_ontology', 'tail' : 'go'}\n",
    "\n",
    "print(type(wandb.config))\n",
    "print(config.homogeneous)\n",
    "print(config.val_ratio)\n",
    "\n",
    "data = load_iric_data(iric_path, featureless=False)\n",
    "data  = T.ToUndirected(merge=True)(data) # Convert the graph to an undirected graph. Creates reverse edges for each edge.\n",
    "data = T.RemoveDuplicatedEdges()(data) # Remove duplicated edges\n",
    "print(data)\n",
    "assert data.validate()\n",
    "\n",
    "train_data, val_data, test_data = split_data(data, config)\n",
    "train_loader, val_loader, test_loader = build_dataloaders(train_data, val_data, test_data, config)\n",
    "\n",
    "batchy = next(iter(train_loader))\n",
    "\n",
    "\n",
    "# # Model to train :\n",
    "# hidden_channels = 176\n",
    "# batch_size      = 4096\n",
    "# epochs          = 200\n",
    "# eval_period     = 2\n",
    "# lin_factor      = 1\n",
    "\n",
    "# use_wandb  = True\n",
    "\n",
    "# params_save_name = f\"PARAMS_ComplEx_6_times_{hidden_channels}_HC_{epochs}_epochs_{batch_size}_BS_on_full_iric\"\n",
    "# model_parameters_path = \"/home/ebutz/ESL2024/data/mapping_datasets_and_model_for_genes_to_phenotypes_iric/\"+params_save_name\n",
    "\n",
    "# #¬†Ontology\n",
    "# ontology_path = \"/home/ebutz/ESL2024/data/go-basic.json.gz\"\n",
    "\n",
    "# # ------------- Cuda ------------- #\n",
    "\n",
    "# print(\"\\nCuda check...\")\n",
    "\n",
    "# device = 'cpu'\n",
    "\n",
    "# # ------------- Loading datas ------------- #\n",
    "\n",
    "# iric = load_iric_data('data/iric.csv', featureless=False)\n",
    "# display(iric)\n",
    "\n",
    "# print(\"\\nLoading iric...\")\n",
    "# mapped_iric = pd.read_pickle(mapped_iric_path)\n",
    "# print(mapped_iric.head())\n",
    "# print('mapped_alt_tails type :', type(mapped_iric.iloc[0]['mapped_alt_tails']))\n",
    "\n",
    "# GO_to_map = mapped_iric.set_index('object')['mapped_object'].to_dict()\n",
    "# map_to_GO = {value: key for key, value in GO_to_map.items()}\n",
    "\n",
    "# if check_dicts:\n",
    "#     looks_ok: bool = True\n",
    "#     for i in tqdm(range(len(list(mapped_iric['object']))), desc = \"Checking GO to MAP dict\"):\n",
    "#         if GO_to_map[mapped_iric['object'][i]]!=mapped_iric['mapped_object'][i] :\n",
    "#             looks_ok = False\n",
    "#     print('GO - Mapping dicts looks ok :', looks_ok)\n",
    "\n",
    "# with open(altails_dict_path, 'rb') as handle:\n",
    "#     mapped_alt_tails = pickle.load(handle)\n",
    "# print(\"Alternative tails dict (first key-value pair):\", list(mapped_alt_tails.items())[0])\n",
    "\n",
    "# # ------------- Loading ontology ------------- #\n",
    "\n",
    "print(\"\\nLoading ontology...\")\n",
    "nxo = from_file(ontology_path)\n",
    "nxo.freeze()\n",
    "pwc.nxo = nxo\n",
    "\n",
    "df = pd.read_csv(iric_path, index_col=0, dtype=str)\n",
    "df['source_node'] = df.index\n",
    "df.columns = [x.lower() for x in df.columns]\n",
    "go_map = get_nodelist(df, 'go')\n",
    "go_to_idx = {node: i for i, node in enumerate(go_map)}\n",
    "idx_to_go = {i: node for i, node in enumerate(go_map)}\n",
    "\n",
    "# # ------------- Making global variables accessibles to pwc ------------- #\n",
    "\n",
    "pwc.map_to_GO        = idx_to_go\n",
    "pwc.mapped_alt_tails = None\n",
    "pwc.device           = device\n",
    "\n",
    "# # ------------- Making datasets ------------- #\n",
    "\n",
    "\n",
    "# print(\"\\nDataset looks valid :\",hetero_iric.validate(raise_on_error=True))\n",
    "\n",
    "# print('All done.')\n",
    "\n",
    "\n",
    "# # Init model\n",
    "\n",
    "\n",
    "gnn_layers = get_gnn_layers(config)\n",
    "norm_layers = get_norm_layers(config, len(data.node_types))\n",
    "\n",
    "model = Model(config, data, norm_layers, gnn_layers).to(device)\n",
    "\n",
    "\n",
    "# ----------------- Loops ----------------- #\n",
    "@timer_func\n",
    "def evaluate(config, loader, model, criterion, compute_all_metrics=False, loader_type='validation', stopper_metric=False):\n",
    "    \"\"\"\n",
    "    Evaluate the model on a given data loader.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : object\n",
    "        An object containing the configuration parameters for the model.    \n",
    "    loader : DataLoader\n",
    "        The data loader to evaluate the model on.\n",
    "    model : Model\n",
    "        The model to evaluate.\n",
    "    criterion : callable\n",
    "        The loss function to use for evaluation.\n",
    "    compute_all_metrics : bool, optional\n",
    "        Whether to compute all metrics or partially. Default is False.\n",
    "    loader_type : str, optional\n",
    "        The type of the loader ('validation' or 'test'). Default is 'validation'.\n",
    "    stopper_metric : str or bool, optional\n",
    "        The metric that dictates when to stop training. If False, only the loss is computed. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A tuple of the evaluation metric and the loss, depending on the value of `stopper_metric`.\n",
    "        If compute_all_metrics is True, the function logs all metrics to W&B.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    num_neg_samples = loader.neg_sampling.amount\n",
    "    with torch.no_grad():\n",
    "        if stopper_metric or compute_all_metrics:\n",
    "            ground_truths = torch.tensor([], device='cpu')\n",
    "            preds = torch.tensor([], device='cpu')\n",
    "            indexes = torch.tensor([], device='cpu')\n",
    "            total_loss, total_examples = 0, 0\n",
    "            index_end = loader.batch_size\n",
    "\n",
    "        for sampled_data in loader:\n",
    "            sampled_data = sampled_data.to(device)\n",
    "\n",
    "            batch_size = len(sampled_data[config.labels['tail']].dst_pos_index)\n",
    "            pred = model(sampled_data, config)\n",
    "            pos_samples = torch.ones(batch_size, device=device)\n",
    "            neg_samples = torch.zeros(num_neg_samples*batch_size, device=device)\n",
    "            ground_truth = torch.cat((pos_samples, neg_samples))\n",
    "\n",
    "            if stopper_metric or compute_all_metrics: # Store preds and truths for all batches, and compute indices to calc metrics\n",
    "                index_pos = torch.arange(end=index_end, start=index_end-batch_size) # index for predictions with pos. ground_truth\n",
    "                index_neg = torch.arange(end=index_end, start=index_end-batch_size).repeat_interleave(num_neg_samples)\n",
    "                index = torch.cat((index_pos, index_neg))\n",
    "                indexes = torch.cat((indexes, index.to('cpu')))\n",
    "                preds = torch.cat((preds, pred.to('cpu')))\n",
    "                ground_truths = torch.cat((ground_truths, ground_truth.to('cpu')))\n",
    "                index_end += batch_size\n",
    "\n",
    "            eval_loss = criterion(pred, ground_truth, gamma=config.gamma, alpha=config.alpha)\n",
    "\n",
    "            # if not stopper_metric: # Just logging loss\n",
    "            #     wandb.log({\"running_val_loss\": eval_loss})\n",
    "            #     break\n",
    "            # else:\n",
    "            total_loss += float(eval_loss) * pred.numel() \n",
    "            total_examples += pred.numel()\n",
    "            eval_loss = total_loss / total_examples\n",
    "\n",
    "            # if stopper_metric and not compute_all_metrics:\n",
    "            #     if index_end >= 2048: # Compute approx. intermediate metric on a few datapoints to speed up hyperopt process\n",
    "            #         break \n",
    "\n",
    "        model.train()\n",
    "\n",
    "        if stopper_metric and not compute_all_metrics: # Compute only the metric that dictates stopping\n",
    "            indexes = indexes.long()\n",
    "\n",
    "            # # Log heatmap between prediction and ground truth. Useful for visualization / debugging. overhead 0.2s per epoch for a single sample.\n",
    "            # heatmap = heatmaps(preds, ground_truths, indexes) \n",
    "            # wandb.log({f\"heatmap\": wandb.Image(heatmap)})\n",
    "            # heatmap.close() # Free up memory\n",
    "\n",
    "            match stopper_metric:\n",
    "                case \"val_loss\":\n",
    "                    eval_loss = total_loss / total_examples\n",
    "                    return eval_loss\n",
    "                \n",
    "                case \"mrr\":\n",
    "                    mrr = RetrievalMRR().to(device)\n",
    "                    return mrr(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_10\":\n",
    "                    hit_at_10 = RetrievalHitRate(top_k=10).to(device)\n",
    "                    return hit_at_10(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_5\":\n",
    "                    hit_at_5 = RetrievalHitRate(top_k=5).to(device)\n",
    "                    return hit_at_5(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_3\":\n",
    "                    hit_at_3 = RetrievalHitRate(top_k=3).to(device)\n",
    "                    return hit_at_3(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case \"hit_at_1\":\n",
    "                    hit_at_1 = RetrievalHitRate(top_k=1).to(device)\n",
    "                    return hit_at_1(preds, ground_truths, indexes=indexes), eval_loss\n",
    "                \n",
    "                case _:\n",
    "                    raise ValueError(f\"Unrecognized stopper metric: '{stopper_metric}'\")\n",
    "                \n",
    "        if compute_all_metrics: # Compute all metrics at the end of training\n",
    "            indexes = indexes.long()\n",
    "            mrr = RetrievalMRR().to(device)\n",
    "            hit_at_10 = RetrievalHitRate(top_k=10).to(device)\n",
    "            hit_at_5 = RetrievalHitRate(top_k=5).to(device)\n",
    "            hit_at_3 = RetrievalHitRate(top_k=3).to(device)\n",
    "            hit_at_1 = RetrievalHitRate(top_k=1).to(device)\n",
    "            \n",
    "            mrr = mrr(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_10 = hit_at_10(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_5 = hit_at_5(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_3 = hit_at_3(preds, ground_truths, indexes=indexes)\n",
    "            hit_at_1 = hit_at_1(preds, ground_truths, indexes=indexes)\n",
    "\n",
    "            wandb.log({\n",
    "                f\"{loader_type}MRR\": mrr, f\"{loader_type}hit_at_10\": hit_at_10, f\"{loader_type}hit_at_5\": hit_at_5, f\"{loader_type}hit_at_3\": hit_at_3, f\"{loader_type}hit_at_1\": hit_at_1\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "model = Model(config, data, norm_layers, gnn_layers).to(device)\n",
    "# print(model)\n",
    "\n",
    "criterion = sigmoid_focal_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "# optimizer = Lion(model.parameters(), lr=config.lr, weight_decay=1e-2)\n",
    "early_stopper = EarlyStopper(frequency=config.stopper_frequency, patience=config.stopper_patience, direction=config.stopper_direction, relative_delta=config.stopper_relative_delta)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "@timer_func\n",
    "def train(config, train_loader, val_loader, model, criterion, optimizer, early_stopper):\n",
    "    for epoch in range(config.epochs):\n",
    "        total_loss = total_examples = 0\n",
    "\n",
    "        for sampled_data in tqdm(train_loader, desc=\"Training\"):\n",
    "\n",
    "            sampled_data = sampled_data.to(device)\n",
    "            pred = model(sampled_data, config)\n",
    "            # print(sampled_data)\n",
    "\n",
    "            true_tails = sampled_data['dst_pos_index']\n",
    "\n",
    "            pos_samples  = torch.ones(len(sampled_data[config.labels['tail']].dst_pos_index), device=device)\n",
    "            neg_samples  = torch.zeros(len(sampled_data[config.labels['tail']].dst_neg_index.view(-1)), device=device) # As many zeroes as there are negative samples * batch_size\n",
    "            ground_truth = torch.cat((pos_samples, neg_samples))\n",
    "            # Add gaussian noise to pos_samples to simulate noisy labels. Added noise must be negative and not exceed 1.\n",
    "            # ground_truth += torch.normal(mean=0, std=1, size=(len(ground_truth),), device=device)\n",
    "            # apply sigmoid\n",
    "            ground_truth = torch.sigmoid(ground_truth)\n",
    "            loss = criterion(pred, ground_truth, gamma=config.gamma, alpha=config.alpha)\n",
    "            wandb.log({\"loss\": loss})\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += float(loss) * pred.numel()\n",
    "            total_examples += pred.numel()\n",
    "        train_loss = total_loss / total_examples\n",
    "        print(f\"Epoch: {epoch:03d}, Avg. Loss: {train_loss:.10f}\")\n",
    "        # scheduler.step()\n",
    "\n",
    "        # Compute metrics and check for early stopping\n",
    "        score, val_loss = evaluate(config, val_loader, model, criterion, stopper_metric=config.stopper_metric)\n",
    "        wandb.log({\"avg_loss\": train_loss, \"val_loss\": val_loss, f\"{config.stopper_metric}\": score})\n",
    "\n",
    "        # early_stopper(score)\n",
    "        # if early_stopper.early_stop:\n",
    "        #     print(\"Early stopping triggered at epoch\", epoch)\n",
    "        #     break\n",
    "\n",
    "    print(\"Training done.\")\n",
    "\n",
    "train(config, train_loader, val_loader, model, criterion, optimizer, early_stopper)\n",
    "evaluate(config,  val_loader, model, criterion, compute_all_metrics = True, loader_type ='validation', stopper_metric = False)\n",
    "evaluate(config, test_loader, model, criterion, compute_all_metrics = True, loader_type ='test'      , stopper_metric = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  genes={\n",
      "    x=[24914, 29],\n",
      "    n_id=[24914],\n",
      "    num_sampled_nodes=[6],\n",
      "    src_index=[1024],\n",
      "  },\n",
      "  go={\n",
      "    x=[42972, 3],\n",
      "    n_id=[42972],\n",
      "    num_sampled_nodes=[6],\n",
      "    dst_pos_index=[1024],\n",
      "    dst_neg_index=[1024, 224],\n",
      "  },\n",
      "  po={\n",
      "    x=[1496, 2],\n",
      "    n_id=[1496],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  traito={\n",
      "    x=[1544, 1],\n",
      "    n_id=[1544],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  prosite_profiles={\n",
      "    x=[622, 1],\n",
      "    n_id=[622],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  prosite_patterns={\n",
      "    x=[652, 1],\n",
      "    n_id=[652],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  superfamily={\n",
      "    x=[950, 1],\n",
      "    n_id=[950],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  panther={\n",
      "    x=[5509, 1],\n",
      "    n_id=[5509],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  prints={\n",
      "    x=[419, 1],\n",
      "    n_id=[419],\n",
      "    num_sampled_nodes=[6],\n",
      "  },\n",
      "  dst_pos_index={},\n",
      "  (genes, interacts_with, genes)={\n",
      "    edge_index=[2, 488927],\n",
      "    e_id=[488927],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, gene_ontology, go)={\n",
      "    edge_index=[2, 32512],\n",
      "    edge_label=[81240],\n",
      "    e_id=[32512],\n",
      "    num_sampled_edges=[5],\n",
      "    input_id=[1024],\n",
      "  },\n",
      "  (genes, trait_ontology, traito)={\n",
      "    edge_index=[2, 7834],\n",
      "    e_id=[7834],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, plant_ontology, po)={\n",
      "    edge_index=[2, 3126],\n",
      "    e_id=[3126],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, profile, prosite_profiles)={\n",
      "    edge_index=[2, 7565],\n",
      "    e_id=[7565],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, pattern, prosite_patterns)={\n",
      "    edge_index=[2, 4223],\n",
      "    e_id=[4223],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, family, superfamily)={\n",
      "    edge_index=[2, 10916],\n",
      "    e_id=[10916],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, panther_id, panther)={\n",
      "    edge_index=[2, 22393],\n",
      "    e_id=[22393],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (genes, prints_id, prints)={\n",
      "    edge_index=[2, 3198],\n",
      "    e_id=[3198],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (go, is_a, go)={\n",
      "    edge_index=[2, 133077],\n",
      "    e_id=[133077],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (po, is_a, po)={\n",
      "    edge_index=[2, 3015],\n",
      "    e_id=[3015],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (traito, is_a, traito)={\n",
      "    edge_index=[2, 3473],\n",
      "    e_id=[3473],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (go, rev_gene_ontology, genes)={\n",
      "    edge_index=[2, 53520],\n",
      "    e_id=[53520],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (traito, rev_trait_ontology, genes)={\n",
      "    edge_index=[2, 15023],\n",
      "    e_id=[15023],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (po, rev_plant_ontology, genes)={\n",
      "    edge_index=[2, 6078],\n",
      "    e_id=[6078],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (prosite_profiles, rev_profile, genes)={\n",
      "    edge_index=[2, 12076],\n",
      "    e_id=[12076],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (prosite_patterns, rev_pattern, genes)={\n",
      "    edge_index=[2, 6639],\n",
      "    e_id=[6639],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (superfamily, rev_family, genes)={\n",
      "    edge_index=[2, 20279],\n",
      "    e_id=[20279],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (panther, rev_panther_id, genes)={\n",
      "    edge_index=[2, 23813],\n",
      "    e_id=[23813],\n",
      "    num_sampled_edges=[5],\n",
      "  },\n",
      "  (prints, rev_prints_id, genes)={\n",
      "    edge_index=[2, 4294],\n",
      "    e_id=[4294],\n",
      "    num_sampled_edges=[5],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(batchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batchy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatchy\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgo\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batchy' is not defined"
     ]
    }
   ],
   "source": [
    "batchy['go']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024])\n",
      "tensor([39535, 10996, 39535,  ..., 26210, 13972, 13283])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trues :\n",
      "torch.Size([1024])\n",
      "tensor([39535, 10996, 39535,  ..., 26210, 13972, 13283])\n",
      "\n",
      "Falses :\n",
      "torch.Size([1024, 224])\n",
      "tensor([[ 2125, 24944,  9479,  ..., 29261,  6555, 32678],\n",
      "        [39537, 33078, 21850,  ..., 14904, 41538, 24025],\n",
      "        [27808, 19883, 14555,  ...,  4757, 25788, 16763],\n",
      "        ...,\n",
      "        [18989, 21549, 25492,  ..., 31450,  8316,   411],\n",
      "        [35346, 28033,  8906,  ..., 41842, 12120, 11520],\n",
      "        [29584, 38174, 38918,  ..., 31595, 20244, 33470]])\n",
      "\n",
      "-1-viewed falses :\n",
      "tensor([ 2125, 24944,  9479,  ..., 31595, 20244, 33470])\n",
      "torch.Size([229376])\n",
      "\n",
      "Elonged_trues :\n",
      "torch.Size([229376])\n",
      "tensor([39535, 39535, 39535,  ..., 13283, 13283, 13283])\n"
     ]
    }
   ],
   "source": [
    "print('Trues :')\n",
    "true_tails = batchy['go']['dst_pos_index']\n",
    "print(true_tails.size())\n",
    "print(true_tails)\n",
    "print('\\nFalses :')\n",
    "false_tails = batchy['go']['dst_neg_index']\n",
    "print(false_tails.size())\n",
    "print(false_tails)\n",
    "\n",
    "print(\"\\n-1-viewed falses :\")\n",
    "viewed_falses = batchy[config.labels['tail']].dst_neg_index.view(-1)\n",
    "print(viewed_falses)\n",
    "print(viewed_falses.size())\n",
    "\n",
    "print(\"\\nElonged_trues :\")\n",
    "elonged_trues = torch.repeat_interleave(true_tails,int(viewed_falses.size()[0]/true_tails.size()[0]))\n",
    "print(elonged_trues.size())\n",
    "print(elonged_trues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10996)\n",
      "tensor(40661)\n",
      "torch.Size([229376])\n",
      "tensor([0.0000, 0.0611, 0.0000,  ..., 0.0000, 0.0000, 0.2084])\n"
     ]
    }
   ],
   "source": [
    "linsims = pwc.lin_sims_for_batch(elonged_trues, viewed_falses)\n",
    "print(linsims.size())\n",
    "print(linsims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos Labels :\n",
      "torch.Size([1024])\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "\n",
      "Neg labels :\n",
      "torch.Size([229376])\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "\n",
      "Lin Neg labels :\n",
      "torch.Size([229376])\n",
      "tensor([0.0000, 0.0611, 0.0000,  ..., 0.0000, 0.0000, 0.2084])\n"
     ]
    }
   ],
   "source": [
    "pos_samples  = torch.ones(len(batchy[config.labels['tail']].dst_pos_index), device=device)\n",
    "neg_samples  = torch.zeros(len(batchy[config.labels['tail']].dst_neg_index.view(-1)), device=device) # As many zeroes as there are negative samples * batch_size\n",
    "lin_neg_samples = linsims\n",
    "ground_truth = torch.cat((pos_samples, neg_samples))\n",
    "lin_ground_truth = torch.cat((pos_samples, lin_neg_samples))\n",
    "\n",
    "            \n",
    "print('Pos Labels :')\n",
    "print(pos_samples.size())\n",
    "print(pos_samples)\n",
    "print('\\nNeg labels :')\n",
    "print(neg_samples.size())\n",
    "print(neg_samples)\n",
    "print('\\nLin Neg labels :')\n",
    "print(lin_neg_samples.size())\n",
    "print(lin_neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ground_truth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mground_truth\u001b[49m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(lin_ground_truth\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ground_truth' is not defined"
     ]
    }
   ],
   "source": [
    "print(ground_truth.size())\n",
    "print(lin_ground_truth.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([230400])\n",
      "tensor([ 0.5346,  0.4036,  0.5318,  ..., -0.0050, -0.0122,  0.0082],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred = model(batchy, config)\n",
    "print(pred.size())\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1625, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1590, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(pred, ground_truth, gamma=config.gamma, alpha=config.alpha)\n",
    "print(loss)\n",
    "lin_loss = criterion(pred, lin_ground_truth, gamma=config.gamma, alpha=config.alpha)\n",
    "print(lin_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1590, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(pred, lin_ground_truth, gamma=config.gamma, alpha=config.alpha)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ground_truth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mground_truth\u001b[49m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnormal(mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ground_truth),), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      2\u001b[0m                 \u001b[38;5;66;03m# apply sigmoid\u001b[39;00m\n\u001b[1;32m      3\u001b[0m ground_truth \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(ground_truth)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ground_truth' is not defined"
     ]
    }
   ],
   "source": [
    "ground_truth += torch.normal(mean=0, std=1, size=(len(ground_truth),), device=device)\n",
    "                # apply sigmoid\n",
    "ground_truth = torch.sigmoid(ground_truth)\n",
    "loss = criterion(pred, ground_truth, gamma=config.gamma, alpha=config.alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
